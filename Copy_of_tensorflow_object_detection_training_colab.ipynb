{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "Copy of tensorflow-object-detection-training-colab.ipynb",
      "version": "0.3.2",
      "provenance": [],
      "collapsed_sections": [],
      "toc_visible": true,
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/ammu11/Resume-analyis/blob/master/Copy_of_tensorflow_object_detection_training_colab.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "uQCnYPVDrsgx",
        "colab_type": "text"
      },
      "source": [
        "# [How to train an object detection model easy for free](https://www.dlology.com/blog/how-to-train-an-object-detection-model-easy-for-free/) | DLology Blog"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "yhzxsJb3dpWq",
        "colab_type": "text"
      },
      "source": [
        "## Configs and Hyperparameters\n",
        "\n",
        "Support a variety of models, you can find more pretrained model from [Tensorflow detection model zoo: COCO-trained models](https://github.com/tensorflow/models/blob/master/research/object_detection/g3doc/detection_model_zoo.md#coco-trained-models), as well as their pipline config files in [object_detection/samples/configs/](https://github.com/tensorflow/models/tree/master/research/object_detection/samples/configs)."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "gnNXNQCjdniL",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# If you forked the repository, you can replace the link.\n",
        "repo_url = 'https://github.com/ammu11/damagecar'\n",
        "\n",
        "# Number of training steps.\n",
        "num_steps = 100000  # 200000\n",
        "\n",
        "# Number of evaluation steps.\n",
        "num_eval_steps = 50\n",
        "\n",
        "MODELS_CONFIG = {\n",
        "    'ssd_mobilenet_v2': {\n",
        "        'model_name': 'ssd_mobilenet_v2_coco_2018_03_29',\n",
        "        'pipeline_file': 'ssd_mobilenet_v2_coco.config',\n",
        "        'batch_size': 12\n",
        "    },\n",
        "    'faster_rcnn_inception_v2': {\n",
        "        'model_name': 'faster_rcnn_inception_v2_coco_2018_01_28',\n",
        "        'pipeline_file': 'faster_rcnn_inception_v2_pets.config',\n",
        "        'batch_size': 12\n",
        "    },\n",
        "    'rfcn_resnet101': {\n",
        "        'model_name': 'rfcn_resnet101_coco_2018_01_28',\n",
        "        'pipeline_file': 'rfcn_resnet101_pets.config',\n",
        "        'batch_size': 8\n",
        "    }\n",
        "}\n",
        "\n",
        "# Pick the model you want to use\n",
        "# Select a model in `MODELS_CONFIG`.\n",
        "selected_model = 'ssd_mobilenet_v2'\n",
        "\n",
        "# Name of the object detection model to use.\n",
        "MODEL = MODELS_CONFIG[selected_model]['model_name']\n",
        "\n",
        "# Name of the pipline file in tensorflow object detection API.\n",
        "pipeline_file = MODELS_CONFIG[selected_model]['pipeline_file']\n",
        "\n",
        "# Training batch size fits in Colabe's Tesla K80 GPU memory for selected model.\n",
        "batch_size = MODELS_CONFIG[selected_model]['batch_size']"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "w4V-XE6kbkc1",
        "colab_type": "text"
      },
      "source": [
        "## Clone the `object_detection_demo` repository or your fork."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "dxc3DmvLQF3z",
        "colab_type": "code",
        "outputId": "044281e2-d827-4cae-c29d-18ead62ed549",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 185
        }
      },
      "source": [
        "import os\n",
        "\n",
        "%cd /content\n",
        "\n",
        "repo_dir_path = os.path.abspath(os.path.join('.', os.path.basename(repo_url)))\n",
        "\n",
        "!git clone {repo_url}\n",
        "%cd {repo_dir_path}\n",
        "!git pull"
      ],
      "execution_count": 2,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "/content\n",
            "Cloning into 'damagecar'...\n",
            "remote: Enumerating objects: 1772, done.\u001b[K\n",
            "remote: Counting objects: 100% (1772/1772), done.\u001b[K\n",
            "remote: Compressing objects: 100% (1171/1171), done.\u001b[K\n",
            "remote: Total 1772 (delta 598), reused 1772 (delta 598), pack-reused 0\n",
            "Receiving objects: 100% (1772/1772), 44.09 MiB | 3.07 MiB/s, done.\n",
            "Resolving deltas: 100% (598/598), done.\n",
            "/content/damagecar\n",
            "Already up to date.\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "bI8__uNS8-ns",
        "colab_type": "text"
      },
      "source": [
        "## Install required packages"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "u-k7uGThXlny",
        "colab_type": "text"
      },
      "source": [
        "## Prepare `tfrecord` files\n",
        "\n",
        "Use the following scripts to generate the `tfrecord` files.\n",
        "```bash\n",
        "# Convert train folder annotation xml files to a single csv file,\n",
        "# generate the `label_map.pbtxt` file to `data/` directory as well.\n",
        "python xml_to_csv.py -i data/images/train -o data/annotations/train_labels.csv -l data/annotations\n",
        "\n",
        "# Convert test folder annotation xml files to a single csv.\n",
        "python xml_to_csv.py -i data/images/test -o data/annotations/test_labels.csv\n",
        "\n",
        "# Generate `train.record`\n",
        "python generate_tfrecord.py --csv_input=data/annotations/train_labels.csv --output_path=data/annotations/train.record --img_path=data/images/train --label_map data/annotations/label_map.pbtxt\n",
        "\n",
        "# Generate `test.record`\n",
        "python generate_tfrecord.py --csv_input=data/annotations/test_labels.csv --output_path=data/annotations/test.record --img_path=data/images/test --label_map data/annotations/label_map.pbtxt\n",
        "```"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ecpHEnka8Kix",
        "colab_type": "code",
        "outputId": "b16565b0-aac9-47d6-f256-e5cd631495c9",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        }
      },
      "source": [
        "%cd /content\n",
        "!git clone --quiet https://github.com/tensorflow/models.git\n",
        "\n",
        "!apt-get install -qq protobuf-compiler python-pil python-lxml python-tk\n",
        "\n",
        "!pip install -q Cython contextlib2 pillow lxml matplotlib\n",
        "\n",
        "!pip install -q pycocotools\n",
        "\n",
        "%cd /content/models/research\n",
        "!protoc object_detection/protos/*.proto --python_out=.\n",
        "\n",
        "import os\n",
        "os.environ['PYTHONPATH'] += ':/content/models/research/:/content/models/research/slim/'\n",
        "\n",
        "!python object_detection/builders/model_builder_test.py"
      ],
      "execution_count": 3,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "/content\n",
            "Selecting previously unselected package python-bs4.\n",
            "(Reading database ... 130942 files and directories currently installed.)\n",
            "Preparing to unpack .../0-python-bs4_4.6.0-1_all.deb ...\n",
            "Unpacking python-bs4 (4.6.0-1) ...\n",
            "Selecting previously unselected package python-pkg-resources.\n",
            "Preparing to unpack .../1-python-pkg-resources_39.0.1-2_all.deb ...\n",
            "Unpacking python-pkg-resources (39.0.1-2) ...\n",
            "Selecting previously unselected package python-chardet.\n",
            "Preparing to unpack .../2-python-chardet_3.0.4-1_all.deb ...\n",
            "Unpacking python-chardet (3.0.4-1) ...\n",
            "Selecting previously unselected package python-six.\n",
            "Preparing to unpack .../3-python-six_1.11.0-2_all.deb ...\n",
            "Unpacking python-six (1.11.0-2) ...\n",
            "Selecting previously unselected package python-webencodings.\n",
            "Preparing to unpack .../4-python-webencodings_0.5-2_all.deb ...\n",
            "Unpacking python-webencodings (0.5-2) ...\n",
            "Selecting previously unselected package python-html5lib.\n",
            "Preparing to unpack .../5-python-html5lib_0.999999999-1_all.deb ...\n",
            "Unpacking python-html5lib (0.999999999-1) ...\n",
            "Selecting previously unselected package python-lxml:amd64.\n",
            "Preparing to unpack .../6-python-lxml_4.2.1-1ubuntu0.1_amd64.deb ...\n",
            "Unpacking python-lxml:amd64 (4.2.1-1ubuntu0.1) ...\n",
            "Selecting previously unselected package python-olefile.\n",
            "Preparing to unpack .../7-python-olefile_0.45.1-1_all.deb ...\n",
            "Unpacking python-olefile (0.45.1-1) ...\n",
            "Selecting previously unselected package python-pil:amd64.\n",
            "Preparing to unpack .../8-python-pil_5.1.0-1_amd64.deb ...\n",
            "Unpacking python-pil:amd64 (5.1.0-1) ...\n",
            "Setting up python-pkg-resources (39.0.1-2) ...\n",
            "Setting up python-six (1.11.0-2) ...\n",
            "Setting up python-bs4 (4.6.0-1) ...\n",
            "Setting up python-lxml:amd64 (4.2.1-1ubuntu0.1) ...\n",
            "Setting up python-olefile (0.45.1-1) ...\n",
            "Processing triggers for man-db (2.8.3-2ubuntu0.1) ...\n",
            "Setting up python-pil:amd64 (5.1.0-1) ...\n",
            "Setting up python-webencodings (0.5-2) ...\n",
            "Setting up python-chardet (3.0.4-1) ...\n",
            "Setting up python-html5lib (0.999999999-1) ...\n",
            "/content/models/research\n",
            "WARNING: Logging before flag parsing goes to stderr.\n",
            "W0708 09:42:02.420719 139947445921664 lazy_loader.py:50] \n",
            "The TensorFlow contrib module will not be included in TensorFlow 2.0.\n",
            "For more information, please see:\n",
            "  * https://github.com/tensorflow/community/blob/master/rfcs/20180907-contrib-sunset.md\n",
            "  * https://github.com/tensorflow/addons\n",
            "  * https://github.com/tensorflow/io (for I/O related ops)\n",
            "If you depend on functionality not listed there, please file an issue.\n",
            "\n",
            "W0708 09:42:02.737601 139947445921664 deprecation_wrapper.py:119] From /content/models/research/slim/nets/inception_resnet_v2.py:373: The name tf.GraphKeys is deprecated. Please use tf.compat.v1.GraphKeys instead.\n",
            "\n",
            "W0708 09:42:02.786802 139947445921664 deprecation_wrapper.py:119] From /content/models/research/slim/nets/mobilenet/mobilenet.py:397: The name tf.nn.avg_pool is deprecated. Please use tf.nn.avg_pool2d instead.\n",
            "\n",
            "Running tests under Python 3.6.8: /usr/bin/python3\n",
            "[ RUN      ] ModelBuilderTest.test_create_faster_rcnn_model_from_config_with_example_miner\n",
            "[       OK ] ModelBuilderTest.test_create_faster_rcnn_model_from_config_with_example_miner\n",
            "[ RUN      ] ModelBuilderTest.test_create_faster_rcnn_models_from_config_faster_rcnn_with_matmul\n",
            "[       OK ] ModelBuilderTest.test_create_faster_rcnn_models_from_config_faster_rcnn_with_matmul\n",
            "[ RUN      ] ModelBuilderTest.test_create_faster_rcnn_models_from_config_faster_rcnn_without_matmul\n",
            "[       OK ] ModelBuilderTest.test_create_faster_rcnn_models_from_config_faster_rcnn_without_matmul\n",
            "[ RUN      ] ModelBuilderTest.test_create_faster_rcnn_models_from_config_mask_rcnn_with_matmul\n",
            "[       OK ] ModelBuilderTest.test_create_faster_rcnn_models_from_config_mask_rcnn_with_matmul\n",
            "[ RUN      ] ModelBuilderTest.test_create_faster_rcnn_models_from_config_mask_rcnn_without_matmul\n",
            "[       OK ] ModelBuilderTest.test_create_faster_rcnn_models_from_config_mask_rcnn_without_matmul\n",
            "[ RUN      ] ModelBuilderTest.test_create_rfcn_model_from_config\n",
            "[       OK ] ModelBuilderTest.test_create_rfcn_model_from_config\n",
            "[ RUN      ] ModelBuilderTest.test_create_ssd_fpn_model_from_config\n",
            "[       OK ] ModelBuilderTest.test_create_ssd_fpn_model_from_config\n",
            "[ RUN      ] ModelBuilderTest.test_create_ssd_models_from_config\n",
            "[       OK ] ModelBuilderTest.test_create_ssd_models_from_config\n",
            "[ RUN      ] ModelBuilderTest.test_invalid_faster_rcnn_batchnorm_update\n",
            "[       OK ] ModelBuilderTest.test_invalid_faster_rcnn_batchnorm_update\n",
            "[ RUN      ] ModelBuilderTest.test_invalid_first_stage_nms_iou_threshold\n",
            "[       OK ] ModelBuilderTest.test_invalid_first_stage_nms_iou_threshold\n",
            "[ RUN      ] ModelBuilderTest.test_invalid_model_config_proto\n",
            "[       OK ] ModelBuilderTest.test_invalid_model_config_proto\n",
            "[ RUN      ] ModelBuilderTest.test_invalid_second_stage_batch_size\n",
            "[       OK ] ModelBuilderTest.test_invalid_second_stage_batch_size\n",
            "[ RUN      ] ModelBuilderTest.test_session\n",
            "[  SKIPPED ] ModelBuilderTest.test_session\n",
            "[ RUN      ] ModelBuilderTest.test_unknown_faster_rcnn_feature_extractor\n",
            "[       OK ] ModelBuilderTest.test_unknown_faster_rcnn_feature_extractor\n",
            "[ RUN      ] ModelBuilderTest.test_unknown_meta_architecture\n",
            "[       OK ] ModelBuilderTest.test_unknown_meta_architecture\n",
            "[ RUN      ] ModelBuilderTest.test_unknown_ssd_feature_extractor\n",
            "[       OK ] ModelBuilderTest.test_unknown_ssd_feature_extractor\n",
            "----------------------------------------------------------------------\n",
            "Ran 16 tests in 0.133s\n",
            "\n",
            "OK (skipped=1)\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ezGDABRXXhPP",
        "colab_type": "code",
        "outputId": "251521fd-0ef2-4cca-d083-e4c25e41bf29",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 373
        }
      },
      "source": [
        "%cd {repo_dir_path}\n",
        "\n",
        "# Convert train folder annotation xml files to a single csv file,\n",
        "# generate the `label_map.pbtxt` file to `data/` directory as well.\n",
        "!python xml_to_csv.py -i data/images/train -o data/annotations/train_labels.csv -l data/annotations\n",
        "\n",
        "# Convert test folder annotation xml files to a single csv.\n",
        "!python xml_to_csv.py -i data/images/test -o data/annotations/test_labels.csv\n",
        "\n",
        "# Generate `train.record`\n",
        "!python generate_tfrecord.py --csv_input=data/annotations/train_labels.csv --output_path=data/annotations/train.record --img_path=data/images/train --label_map data/annotations/label_map.pbtxt\n",
        "\n",
        "# Generate `test.record`\n",
        "!python generate_tfrecord.py --csv_input=data/annotations/test_labels.csv --output_path=data/annotations/test.record --img_path=data/images/test --label_map data/annotations/label_map.pbtxt"
      ],
      "execution_count": 14,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "/content/damagecar\n",
            "Successfully converted xml to csv.\n",
            "Generate `data/annotations/label_map.pbtxt`\n",
            "Successfully converted xml to csv.\n",
            "WARNING: Logging before flag parsing goes to stderr.\n",
            "W0708 09:46:07.293780 140666413160320 deprecation_wrapper.py:119] From generate_tfrecord.py:132: The name tf.app.run is deprecated. Please use tf.compat.v1.app.run instead.\n",
            "\n",
            "W0708 09:46:07.294379 140666413160320 deprecation_wrapper.py:119] From generate_tfrecord.py:105: The name tf.python_io.TFRecordWriter is deprecated. Please use tf.io.TFRecordWriter instead.\n",
            "\n",
            "W0708 09:46:07.305840 140666413160320 deprecation_wrapper.py:119] From /content/models/research/object_detection/utils/label_map_util.py:132: The name tf.gfile.GFile is deprecated. Please use tf.io.gfile.GFile instead.\n",
            "\n",
            "Successfully created the TFRecords: /content/damagecar/data/annotations/train.record\n",
            "WARNING: Logging before flag parsing goes to stderr.\n",
            "W0708 09:46:12.453377 140007814207360 deprecation_wrapper.py:119] From generate_tfrecord.py:132: The name tf.app.run is deprecated. Please use tf.compat.v1.app.run instead.\n",
            "\n",
            "W0708 09:46:12.453986 140007814207360 deprecation_wrapper.py:119] From generate_tfrecord.py:105: The name tf.python_io.TFRecordWriter is deprecated. Please use tf.io.TFRecordWriter instead.\n",
            "\n",
            "W0708 09:46:12.464165 140007814207360 deprecation_wrapper.py:119] From /content/models/research/object_detection/utils/label_map_util.py:132: The name tf.gfile.GFile is deprecated. Please use tf.io.gfile.GFile instead.\n",
            "\n",
            "Successfully created the TFRecords: /content/damagecar/data/annotations/test.record\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "tgd-fzAIkZlV",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "test_record_fname = '/content/damagecar/data/annotations/test.record'\n",
        "train_record_fname = '/content/damagecar/data/annotations/train.record'\n",
        "label_map_pbtxt_fname = '/content/damagecar/data/annotations/label_map.pbtxt'\n"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "iCNYAaC7w6N8",
        "colab_type": "text"
      },
      "source": [
        "## Download base model"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "orDCj6ihgUMR",
        "colab_type": "code",
        "outputId": "dc2b7d1e-33d0-4065-93a9-84b230fd3912",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        }
      },
      "source": [
        "%cd /content/models/research\n",
        "\n",
        "import os\n",
        "import shutil\n",
        "import glob\n",
        "import urllib.request\n",
        "import tarfile\n",
        "MODEL_FILE = MODEL + '.tar.gz'\n",
        "DOWNLOAD_BASE = 'http://download.tensorflow.org/models/object_detection/'\n",
        "DEST_DIR = '/content/models/research/pretrained_model'\n",
        "\n",
        "if not (os.path.exists(MODEL_FILE)):\n",
        "    urllib.request.urlretrieve(DOWNLOAD_BASE + MODEL_FILE, MODEL_FILE)\n",
        "\n",
        "tar = tarfile.open(MODEL_FILE)\n",
        "tar.extractall()\n",
        "tar.close()\n",
        "\n",
        "os.remove(MODEL_FILE)\n",
        "if (os.path.exists(DEST_DIR)):\n",
        "    shutil.rmtree(DEST_DIR)\n",
        "os.rename(MODEL, DEST_DIR)"
      ],
      "execution_count": 7,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "/content/models/research\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "pGhvAObeiIix",
        "colab_type": "code",
        "outputId": "c28502d8-714f-4acd-e8fd-74ee547463b8",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 202
        }
      },
      "source": [
        "!echo {DEST_DIR}\n",
        "!ls -alh {DEST_DIR}"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "/content/models/research/pretrained_model\n",
            "total 135M\n",
            "drwxr-xr-x  3 345018 89939 4.0K Mar 30  2018 .\n",
            "drwxr-xr-x 71 root   root  4.0K Jul  8 00:20 ..\n",
            "-rw-r--r--  1 345018 89939   77 Mar 30  2018 checkpoint\n",
            "-rw-r--r--  1 345018 89939  67M Mar 30  2018 frozen_inference_graph.pb\n",
            "-rw-r--r--  1 345018 89939  65M Mar 30  2018 model.ckpt.data-00000-of-00001\n",
            "-rw-r--r--  1 345018 89939  15K Mar 30  2018 model.ckpt.index\n",
            "-rw-r--r--  1 345018 89939 3.4M Mar 30  2018 model.ckpt.meta\n",
            "-rw-r--r--  1 345018 89939 4.2K Mar 30  2018 pipeline.config\n",
            "drwxr-xr-x  3 345018 89939 4.0K Mar 30  2018 saved_model\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "UHnxlfRznPP3",
        "colab_type": "code",
        "outputId": "09379d32-1a87-4c4d-9486-e702bd64fc3c",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        }
      },
      "source": [
        "fine_tune_checkpoint = os.path.join(DEST_DIR, \"model.ckpt\")\n",
        "fine_tune_checkpoint"
      ],
      "execution_count": 8,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "'/content/models/research/pretrained_model/model.ckpt'"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 8
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "MvwtHlLOeRJD",
        "colab_type": "text"
      },
      "source": [
        "## Configuring a Training Pipeline"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "dIhw7IdpLuiU",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "import os\n",
        "pipeline_fname = os.path.join('/content/models/research/object_detection/samples/configs/', pipeline_file)\n",
        "\n",
        "assert os.path.isfile(pipeline_fname), '`{}` not exist'.format(pipeline_fname)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "fG1nCNpUXcRU",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def get_num_classes(pbtxt_fname):\n",
        "    from object_detection.utils import label_map_util\n",
        "    label_map = label_map_util.load_labelmap(pbtxt_fname)\n",
        "    categories = label_map_util.convert_label_map_to_categories(\n",
        "        label_map, max_num_classes=90, use_display_name=True)\n",
        "    category_index = label_map_util.create_category_index(categories)\n",
        "    return len(category_index.keys())"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "YjtCbLF2i0wI",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "import re\n",
        "\n",
        "num_classes = get_num_classes(label_map_pbtxt_fname)\n",
        "with open(pipeline_fname) as f:\n",
        "    s = f.read()\n",
        "with open(pipeline_fname, 'w') as f:\n",
        "    \n",
        "    # fine_tune_checkpoint\n",
        "    s = re.sub('fine_tune_checkpoint: \".*?\"',\n",
        "               'fine_tune_checkpoint: \"{}\"'.format(fine_tune_checkpoint), s)\n",
        "    \n",
        "    # tfrecord files train and test.\n",
        "    s = re.sub(\n",
        "        '(input_path: \".*?)(train.record)(.*?\")', 'input_path: \"{}\"'.format(train_record_fname), s)\n",
        "    s = re.sub(\n",
        "        '(input_path: \".*?)(val.record)(.*?\")', 'input_path: \"{}\"'.format(test_record_fname), s)\n",
        "\n",
        "    # label_map_path\n",
        "    s = re.sub(\n",
        "        'label_map_path: \".*?\"', 'label_map_path: \"{}\"'.format(label_map_pbtxt_fname), s)\n",
        "\n",
        "    # Set training batch_size.\n",
        "    s = re.sub('batch_size: [0-9]+',\n",
        "               'batch_size: {}'.format(batch_size), s)\n",
        "\n",
        "    # Set training steps, num_steps\n",
        "    s = re.sub('num_steps: [0-9]+',\n",
        "               'num_steps: {}'.format(num_steps), s)\n",
        "    \n",
        "    # Set number of classes num_classes.\n",
        "    s = re.sub('num_classes: [0-9]+',\n",
        "               'num_classes: {}'.format(num_classes), s)\n",
        "    f.write(s)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "GH0MEEanocn6",
        "colab_type": "code",
        "outputId": "49d86f44-727e-4d61-bfc8-d12d67bb8726",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        }
      },
      "source": [
        "!cat {pipeline_fname}"
      ],
      "execution_count": 18,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "# SSD with Mobilenet v2 configuration for MSCOCO Dataset.\n",
            "# Users should configure the fine_tune_checkpoint field in the train config as\n",
            "# well as the label_map_path and input_path fields in the train_input_reader and\n",
            "# eval_input_reader. Search for \"PATH_TO_BE_CONFIGURED\" to find the fields that\n",
            "# should be configured.\n",
            "\n",
            "model {\n",
            "  ssd {\n",
            "    num_classes: 11\n",
            "    box_coder {\n",
            "      faster_rcnn_box_coder {\n",
            "        y_scale: 10.0\n",
            "        x_scale: 10.0\n",
            "        height_scale: 5.0\n",
            "        width_scale: 5.0\n",
            "      }\n",
            "    }\n",
            "    matcher {\n",
            "      argmax_matcher {\n",
            "        matched_threshold: 0.5\n",
            "        unmatched_threshold: 0.5\n",
            "        ignore_thresholds: false\n",
            "        negatives_lower_than_unmatched: true\n",
            "        force_match_for_each_row: true\n",
            "      }\n",
            "    }\n",
            "    similarity_calculator {\n",
            "      iou_similarity {\n",
            "      }\n",
            "    }\n",
            "    anchor_generator {\n",
            "      ssd_anchor_generator {\n",
            "        num_layers: 6\n",
            "        min_scale: 0.2\n",
            "        max_scale: 0.95\n",
            "        aspect_ratios: 1.0\n",
            "        aspect_ratios: 2.0\n",
            "        aspect_ratios: 0.5\n",
            "        aspect_ratios: 3.0\n",
            "        aspect_ratios: 0.3333\n",
            "      }\n",
            "    }\n",
            "    image_resizer {\n",
            "      fixed_shape_resizer {\n",
            "        height: 300\n",
            "        width: 300\n",
            "      }\n",
            "    }\n",
            "    box_predictor {\n",
            "      convolutional_box_predictor {\n",
            "        min_depth: 0\n",
            "        max_depth: 0\n",
            "        num_layers_before_predictor: 0\n",
            "        use_dropout: false\n",
            "        dropout_keep_probability: 0.8\n",
            "        kernel_size: 1\n",
            "        box_code_size: 4\n",
            "        apply_sigmoid_to_scores: false\n",
            "        conv_hyperparams {\n",
            "          activation: RELU_6,\n",
            "          regularizer {\n",
            "            l2_regularizer {\n",
            "              weight: 0.00004\n",
            "            }\n",
            "          }\n",
            "          initializer {\n",
            "            truncated_normal_initializer {\n",
            "              stddev: 0.03\n",
            "              mean: 0.0\n",
            "            }\n",
            "          }\n",
            "          batch_norm {\n",
            "            train: true,\n",
            "            scale: true,\n",
            "            center: true,\n",
            "            decay: 0.9997,\n",
            "            epsilon: 0.001,\n",
            "          }\n",
            "        }\n",
            "      }\n",
            "    }\n",
            "    feature_extractor {\n",
            "      type: 'ssd_mobilenet_v2'\n",
            "      min_depth: 16\n",
            "      depth_multiplier: 1.0\n",
            "      conv_hyperparams {\n",
            "        activation: RELU_6,\n",
            "        regularizer {\n",
            "          l2_regularizer {\n",
            "            weight: 0.00004\n",
            "          }\n",
            "        }\n",
            "        initializer {\n",
            "          truncated_normal_initializer {\n",
            "            stddev: 0.03\n",
            "            mean: 0.0\n",
            "          }\n",
            "        }\n",
            "        batch_norm {\n",
            "          train: true,\n",
            "          scale: true,\n",
            "          center: true,\n",
            "          decay: 0.9997,\n",
            "          epsilon: 0.001,\n",
            "        }\n",
            "      }\n",
            "    }\n",
            "    loss {\n",
            "      classification_loss {\n",
            "        weighted_sigmoid {\n",
            "        }\n",
            "      }\n",
            "      localization_loss {\n",
            "        weighted_smooth_l1 {\n",
            "        }\n",
            "      }\n",
            "      hard_example_miner {\n",
            "        num_hard_examples: 3000\n",
            "        iou_threshold: 0.99\n",
            "        loss_type: CLASSIFICATION\n",
            "        max_negatives_per_positive: 3\n",
            "        min_negatives_per_image: 3\n",
            "      }\n",
            "      classification_weight: 1.0\n",
            "      localization_weight: 1.0\n",
            "    }\n",
            "    normalize_loss_by_num_matches: true\n",
            "    post_processing {\n",
            "      batch_non_max_suppression {\n",
            "        score_threshold: 1e-8\n",
            "        iou_threshold: 0.6\n",
            "        max_detections_per_class: 100\n",
            "        max_total_detections: 100\n",
            "      }\n",
            "      score_converter: SIGMOID\n",
            "    }\n",
            "  }\n",
            "}\n",
            "\n",
            "train_config: {\n",
            "  batch_size: 12\n",
            "  optimizer {\n",
            "    rms_prop_optimizer: {\n",
            "      learning_rate: {\n",
            "        exponential_decay_learning_rate {\n",
            "          initial_learning_rate: 0.004\n",
            "          decay_steps: 800720\n",
            "          decay_factor: 0.95\n",
            "        }\n",
            "      }\n",
            "      momentum_optimizer_value: 0.9\n",
            "      decay: 0.9\n",
            "      epsilon: 1.0\n",
            "    }\n",
            "  }\n",
            "  fine_tune_checkpoint: \"/content/models/research/pretrained_model/model.ckpt\"\n",
            "  fine_tune_checkpoint_type:  \"detection\"\n",
            "  # Note: The below line limits the training process to 200K steps, which we\n",
            "  # empirically found to be sufficient enough to train the pets dataset. This\n",
            "  # effectively bypasses the learning rate schedule (the learning rate will\n",
            "  # never decay). Remove the below line to train indefinitely.\n",
            "  num_steps: 100000\n",
            "  data_augmentation_options {\n",
            "    random_horizontal_flip {\n",
            "    }\n",
            "  }\n",
            "  data_augmentation_options {\n",
            "    ssd_random_crop {\n",
            "    }\n",
            "  }\n",
            "}\n",
            "\n",
            "train_input_reader: {\n",
            "  tf_record_input_reader {\n",
            "    input_path: \"/content/damagecar/data/annotations/train.record\"\n",
            "  }\n",
            "  label_map_path: \"/content/damagecar/data/annotations/label_map.pbtxt\"\n",
            "}\n",
            "\n",
            "eval_config: {\n",
            "  num_examples: 8000\n",
            "  # Note: The below line limits the evaluation process to 10 evaluations.\n",
            "  # Remove the below line to evaluate indefinitely.\n",
            "  max_evals: 10\n",
            "}\n",
            "\n",
            "eval_input_reader: {\n",
            "  tf_record_input_reader {\n",
            "    input_path: \"/content/damagecar/data/annotations/test.record\"\n",
            "  }\n",
            "  label_map_path: \"/content/damagecar/data/annotations/label_map.pbtxt\"\n",
            "  shuffle: false\n",
            "  num_readers: 1\n",
            "}"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "f11w0uO3jFCB",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "model_dir = 'training/'\n",
        "# Optionally remove content in output model directory to fresh start.\n",
        "!rm -rf {model_dir}\n",
        "os.makedirs(model_dir, exist_ok=True)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "23TECXvNezIF",
        "colab_type": "text"
      },
      "source": [
        "## Run Tensorboard(Optional)"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "0H2PZs-mSCmO",
        "colab_type": "code",
        "outputId": "698ebddc-0840-4fe8-8866-c49f697b0180",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 235
        }
      },
      "source": [
        "!wget https://bin.equinox.io/c/4VmDzA7iaHb/ngrok-stable-linux-amd64.zip\n",
        "!unzip -o ngrok-stable-linux-amd64.zip"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "--2019-07-08 00:20:46--  https://bin.equinox.io/c/4VmDzA7iaHb/ngrok-stable-linux-amd64.zip\n",
            "Resolving bin.equinox.io (bin.equinox.io)... 52.2.175.150, 52.21.103.149, 52.71.139.107, ...\n",
            "Connecting to bin.equinox.io (bin.equinox.io)|52.2.175.150|:443... connected.\n",
            "HTTP request sent, awaiting response... 200 OK\n",
            "Length: 17556757 (17M) [application/octet-stream]\n",
            "Saving to: ‘ngrok-stable-linux-amd64.zip’\n",
            "\n",
            "\r          ngrok-sta   0%[                    ]       0  --.-KB/s               \r         ngrok-stab   8%[>                   ]   1.44M  7.18MB/s               \rngrok-stable-linux- 100%[===================>]  16.74M  44.3MB/s    in 0.4s    \n",
            "\n",
            "2019-07-08 00:20:46 (44.3 MB/s) - ‘ngrok-stable-linux-amd64.zip’ saved [17556757/17556757]\n",
            "\n",
            "Archive:  ngrok-stable-linux-amd64.zip\n",
            "  inflating: ngrok                   \n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "G8o6r1o5SC5M",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "LOG_DIR = model_dir\n",
        "get_ipython().system_raw(\n",
        "    'tensorboard --logdir {} --host 0.0.0.0 --port 6006 &'\n",
        "    .format(LOG_DIR)\n",
        ")"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Ge1OX7gcSC7S",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "get_ipython().system_raw('./ngrok http 6006 &')"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "hH8MriBXRHob",
        "colab_type": "text"
      },
      "source": [
        ""
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "m5GSGxZNh8rp",
        "colab_type": "text"
      },
      "source": [
        "### Get Tensorboard link"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "cuLkqzgOR6H9",
        "colab_type": "code",
        "outputId": "f2727e6e-c36c-43fc-cacc-5cb35624e25c",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        }
      },
      "source": [
        "print(\"model_training part\")\n",
        "!python /content/models/research/object_detection/model_main.py \\\n",
        "    --pipeline_config_path={pipeline_fname} \\\n",
        "    --model_dir={model_dir} \\\n",
        "    --alsologtostderr \\\n",
        "    --num_train_steps={num_steps} \\\n",
        "    --num_eval_steps={num_eval_steps}"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "model_training part\n",
            "WARNING: Logging before flag parsing goes to stderr.\n",
            "W0708 09:47:11.164511 140282142955392 lazy_loader.py:50] \n",
            "The TensorFlow contrib module will not be included in TensorFlow 2.0.\n",
            "For more information, please see:\n",
            "  * https://github.com/tensorflow/community/blob/master/rfcs/20180907-contrib-sunset.md\n",
            "  * https://github.com/tensorflow/addons\n",
            "  * https://github.com/tensorflow/io (for I/O related ops)\n",
            "If you depend on functionality not listed there, please file an issue.\n",
            "\n",
            "W0708 09:47:11.196928 140282142955392 deprecation_wrapper.py:119] From /content/models/research/slim/nets/inception_resnet_v2.py:373: The name tf.GraphKeys is deprecated. Please use tf.compat.v1.GraphKeys instead.\n",
            "\n",
            "W0708 09:47:11.206867 140282142955392 deprecation_wrapper.py:119] From /content/models/research/slim/nets/mobilenet/mobilenet.py:397: The name tf.nn.avg_pool is deprecated. Please use tf.nn.avg_pool2d instead.\n",
            "\n",
            "W0708 09:47:11.250693 140282142955392 deprecation_wrapper.py:119] From /content/models/research/object_detection/model_main.py:109: The name tf.app.run is deprecated. Please use tf.compat.v1.app.run instead.\n",
            "\n",
            "W0708 09:47:11.251512 140282142955392 deprecation_wrapper.py:119] From /content/models/research/object_detection/utils/config_util.py:98: The name tf.gfile.GFile is deprecated. Please use tf.io.gfile.GFile instead.\n",
            "\n",
            "W0708 09:47:11.255331 140282142955392 deprecation_wrapper.py:119] From /content/models/research/object_detection/model_lib.py:614: The name tf.logging.warning is deprecated. Please use tf.compat.v1.logging.warning instead.\n",
            "\n",
            "W0708 09:47:11.255441 140282142955392 model_lib.py:615] Forced number of epochs for all eval validations to be 1.\n",
            "W0708 09:47:11.255542 140282142955392 deprecation_wrapper.py:119] From /content/models/research/object_detection/utils/config_util.py:484: The name tf.logging.info is deprecated. Please use tf.compat.v1.logging.info instead.\n",
            "\n",
            "I0708 09:47:11.255608 140282142955392 config_util.py:484] Maybe overwriting train_steps: 100000\n",
            "I0708 09:47:11.255679 140282142955392 config_util.py:484] Maybe overwriting sample_1_of_n_eval_examples: 1\n",
            "I0708 09:47:11.255748 140282142955392 config_util.py:484] Maybe overwriting use_bfloat16: False\n",
            "I0708 09:47:11.255812 140282142955392 config_util.py:484] Maybe overwriting eval_num_epochs: 1\n",
            "I0708 09:47:11.255873 140282142955392 config_util.py:484] Maybe overwriting load_pretrained: True\n",
            "I0708 09:47:11.255934 140282142955392 config_util.py:494] Ignoring config override key: load_pretrained\n",
            "W0708 09:47:11.256029 140282142955392 model_lib.py:631] Expected number of evaluation epochs is 1, but instead encountered `eval_on_train_input_config.num_epochs` = 0. Overwriting `num_epochs` to 1.\n",
            "I0708 09:47:11.256105 140282142955392 model_lib.py:666] create_estimator_and_inputs: use_tpu False, export_to_tpu False\n",
            "I0708 09:47:11.256538 140282142955392 estimator.py:209] Using config: {'_model_dir': 'training/', '_tf_random_seed': None, '_save_summary_steps': 100, '_save_checkpoints_steps': None, '_save_checkpoints_secs': 600, '_session_config': allow_soft_placement: true\n",
            "graph_options {\n",
            "  rewrite_options {\n",
            "    meta_optimizer_iterations: ONE\n",
            "  }\n",
            "}\n",
            ", '_keep_checkpoint_max': 5, '_keep_checkpoint_every_n_hours': 10000, '_log_step_count_steps': 100, '_train_distribute': None, '_device_fn': None, '_protocol': None, '_eval_distribute': None, '_experimental_distribute': None, '_experimental_max_worker_delay_secs': None, '_service': None, '_cluster_spec': <tensorflow.python.training.server_lib.ClusterSpec object at 0x7f95ace05860>, '_task_type': 'worker', '_task_id': 0, '_global_id_in_cluster': 0, '_master': '', '_evaluation_master': '', '_is_chief': True, '_num_ps_replicas': 0, '_num_worker_replicas': 1}\n",
            "W0708 09:47:11.256720 140282142955392 model_fn.py:630] Estimator's model_fn (<function create_model_fn.<locals>.model_fn at 0x7f95acdfd6a8>) includes params argument, but params are not passed to Estimator.\n",
            "I0708 09:47:11.257600 140282142955392 estimator_training.py:186] Not using Distribute Coordinator.\n",
            "I0708 09:47:11.257770 140282142955392 training.py:612] Running training and evaluation locally (non-distributed).\n",
            "I0708 09:47:11.257996 140282142955392 training.py:700] Start train and evaluate loop. The evaluate will happen after every checkpoint. Checkpoint frequency is determined based on RunConfig arguments: save_checkpoints_steps None or save_checkpoints_secs 600.\n",
            "W0708 09:47:11.262795 140282142955392 deprecation.py:323] From /usr/local/lib/python3.6/dist-packages/tensorflow/python/training/training_util.py:236: Variable.initialized_value (from tensorflow.python.ops.variables) is deprecated and will be removed in a future version.\n",
            "Instructions for updating:\n",
            "Use Variable.read_value. Variables in 2.X are initialized automatically both in eager and graph (inside tf.defun) contexts.\n",
            "W0708 09:47:11.274385 140282142955392 deprecation_wrapper.py:119] From /content/models/research/object_detection/data_decoders/tf_example_decoder.py:177: The name tf.FixedLenFeature is deprecated. Please use tf.io.FixedLenFeature instead.\n",
            "\n",
            "W0708 09:47:11.274585 140282142955392 deprecation_wrapper.py:119] From /content/models/research/object_detection/data_decoders/tf_example_decoder.py:192: The name tf.VarLenFeature is deprecated. Please use tf.io.VarLenFeature instead.\n",
            "\n",
            "W0708 09:47:11.290591 140282142955392 deprecation_wrapper.py:119] From /content/models/research/object_detection/builders/dataset_builder.py:64: The name tf.gfile.Glob is deprecated. Please use tf.io.gfile.glob instead.\n",
            "\n",
            "W0708 09:47:11.295221 140282142955392 dataset_builder.py:72] num_readers has been reduced to 1 to match input file shards.\n",
            "W0708 09:47:11.300349 140282142955392 deprecation.py:323] From /content/models/research/object_detection/builders/dataset_builder.py:86: parallel_interleave (from tensorflow.contrib.data.python.ops.interleave_ops) is deprecated and will be removed in a future version.\n",
            "Instructions for updating:\n",
            "Use `tf.data.experimental.parallel_interleave(...)`.\n",
            "W0708 09:47:11.300500 140282142955392 deprecation.py:323] From /usr/local/lib/python3.6/dist-packages/tensorflow/contrib/data/python/ops/interleave_ops.py:77: parallel_interleave (from tensorflow.python.data.experimental.ops.interleave_ops) is deprecated and will be removed in a future version.\n",
            "Instructions for updating:\n",
            "Use `tf.data.Dataset.interleave(map_func, cycle_length, block_length, num_parallel_calls=tf.data.experimental.AUTOTUNE)` instead. If sloppy execution is desired, use `tf.data.Options.experimental_determinstic`.\n",
            "W0708 09:47:11.323525 140282142955392 deprecation.py:323] From /content/models/research/object_detection/builders/dataset_builder.py:155: DatasetV1.map_with_legacy_function (from tensorflow.python.data.ops.dataset_ops) is deprecated and will be removed in a future version.\n",
            "Instructions for updating:\n",
            "Use `tf.data.Dataset.map()\n",
            "W0708 09:47:11.502365 140282142955392 deprecation_wrapper.py:119] From /content/models/research/object_detection/utils/ops.py:485: The name tf.is_nan is deprecated. Please use tf.math.is_nan instead.\n",
            "\n",
            "W0708 09:47:11.506286 140282142955392 deprecation.py:323] From /content/models/research/object_detection/utils/ops.py:487: add_dispatch_support.<locals>.wrapper (from tensorflow.python.ops.array_ops) is deprecated and will be removed in a future version.\n",
            "Instructions for updating:\n",
            "Use tf.where in 2.0, which has the same broadcast rule as np.where\n",
            "W0708 09:47:11.551354 140282142955392 deprecation_wrapper.py:119] From /content/models/research/object_detection/core/preprocessor.py:512: The name tf.random_uniform is deprecated. Please use tf.random.uniform instead.\n",
            "\n",
            "W0708 09:47:11.605746 140282142955392 deprecation.py:323] From /content/models/research/object_detection/core/preprocessor.py:188: sample_distorted_bounding_box (from tensorflow.python.ops.image_ops_impl) is deprecated and will be removed in a future version.\n",
            "Instructions for updating:\n",
            "`seed2` arg is deprecated.Use sample_distorted_bounding_box_v2 instead.\n",
            "W0708 09:47:12.492068 140282142955392 deprecation_wrapper.py:119] From /content/models/research/object_detection/core/preprocessor.py:2515: The name tf.image.resize_images is deprecated. Please use tf.image.resize instead.\n",
            "\n",
            "W0708 09:47:13.065395 140282142955392 deprecation.py:323] From /content/models/research/object_detection/builders/dataset_builder.py:158: batch_and_drop_remainder (from tensorflow.contrib.data.python.ops.batching) is deprecated and will be removed in a future version.\n",
            "Instructions for updating:\n",
            "Use `tf.data.Dataset.batch(..., drop_remainder=True)`.\n",
            "I0708 09:47:13.078853 140282142955392 estimator.py:1145] Calling model_fn.\n",
            "I0708 09:47:16.834029 140282142955392 convolutional_box_predictor.py:151] depth of additional conv before box predictor: 0\n",
            "I0708 09:47:16.873012 140282142955392 convolutional_box_predictor.py:151] depth of additional conv before box predictor: 0\n",
            "I0708 09:47:16.910065 140282142955392 convolutional_box_predictor.py:151] depth of additional conv before box predictor: 0\n",
            "I0708 09:47:16.945131 140282142955392 convolutional_box_predictor.py:151] depth of additional conv before box predictor: 0\n",
            "I0708 09:47:16.980965 140282142955392 convolutional_box_predictor.py:151] depth of additional conv before box predictor: 0\n",
            "I0708 09:47:17.015462 140282142955392 convolutional_box_predictor.py:151] depth of additional conv before box predictor: 0\n",
            "W0708 09:47:17.058133 140282142955392 deprecation_wrapper.py:119] From /content/models/research/object_detection/utils/variables_helper.py:134: The name tf.train.NewCheckpointReader is deprecated. Please use tf.compat.v1.train.NewCheckpointReader instead.\n",
            "\n",
            "W0708 09:47:17.063674 140282142955392 variables_helper.py:149] Variable [FeatureExtractor/MobilenetV2/layer_19_2_Conv2d_2_3x3_s2_512/weights] is available in checkpoint, but has an incompatible shape with model variable. Checkpoint shape: [[1, 1, 256, 512]], model variable shape: [[3, 3, 256, 512]]. This variable will not be initialized from the checkpoint.\n",
            "W0708 09:47:17.063834 140282142955392 variables_helper.py:149] Variable [FeatureExtractor/MobilenetV2/layer_19_2_Conv2d_3_3x3_s2_256/weights] is available in checkpoint, but has an incompatible shape with model variable. Checkpoint shape: [[1, 1, 128, 256]], model variable shape: [[3, 3, 128, 256]]. This variable will not be initialized from the checkpoint.\n",
            "W0708 09:47:17.063953 140282142955392 variables_helper.py:149] Variable [FeatureExtractor/MobilenetV2/layer_19_2_Conv2d_4_3x3_s2_256/weights] is available in checkpoint, but has an incompatible shape with model variable. Checkpoint shape: [[1, 1, 128, 256]], model variable shape: [[3, 3, 128, 256]]. This variable will not be initialized from the checkpoint.\n",
            "W0708 09:47:17.064071 140282142955392 variables_helper.py:149] Variable [FeatureExtractor/MobilenetV2/layer_19_2_Conv2d_5_3x3_s2_128/weights] is available in checkpoint, but has an incompatible shape with model variable. Checkpoint shape: [[1, 1, 64, 128]], model variable shape: [[3, 3, 64, 128]]. This variable will not be initialized from the checkpoint.\n",
            "W0708 09:47:17.064235 140282142955392 deprecation_wrapper.py:119] From /content/models/research/object_detection/model_lib.py:346: The name tf.train.init_from_checkpoint is deprecated. Please use tf.compat.v1.train.init_from_checkpoint instead.\n",
            "\n",
            "W0708 09:47:20.471452 140282142955392 deprecation_wrapper.py:119] From /content/models/research/object_detection/meta_architectures/ssd_meta_arch.py:1066: The name tf.summary.scalar is deprecated. Please use tf.compat.v1.summary.scalar instead.\n",
            "\n",
            "W0708 09:47:20.478545 140282142955392 deprecation_wrapper.py:119] From /content/models/research/object_detection/core/losses.py:172: The name tf.losses.huber_loss is deprecated. Please use tf.compat.v1.losses.huber_loss instead.\n",
            "\n",
            "W0708 09:47:20.479937 140282142955392 deprecation_wrapper.py:119] From /content/models/research/object_detection/core/losses.py:178: The name tf.losses.Reduction is deprecated. Please use tf.compat.v1.losses.Reduction instead.\n",
            "\n",
            "W0708 09:47:20.844692 140282142955392 deprecation_wrapper.py:119] From /content/models/research/object_detection/model_lib.py:373: The name tf.train.get_or_create_global_step is deprecated. Please use tf.compat.v1.train.get_or_create_global_step instead.\n",
            "\n",
            "W0708 09:47:20.845034 140282142955392 deprecation_wrapper.py:119] From /content/models/research/object_detection/utils/learning_schedules.py:61: The name tf.train.exponential_decay is deprecated. Please use tf.compat.v1.train.exponential_decay instead.\n",
            "\n",
            "W0708 09:47:20.855079 140282142955392 deprecation_wrapper.py:119] From /content/models/research/object_detection/builders/optimizer_builder.py:47: The name tf.train.RMSPropOptimizer is deprecated. Please use tf.compat.v1.train.RMSPropOptimizer instead.\n",
            "\n",
            "W0708 09:47:23.028229 140282142955392 deprecation.py:506] From /usr/local/lib/python3.6/dist-packages/tensorflow/python/training/rmsprop.py:119: calling Ones.__init__ (from tensorflow.python.ops.init_ops) with dtype is deprecated and will be removed in a future version.\n",
            "Instructions for updating:\n",
            "Call initializer instance with the dtype argument instead of passing it to the constructor\n",
            "I0708 09:47:30.334992 140282142955392 estimator.py:1147] Done calling model_fn.\n",
            "I0708 09:47:30.336438 140282142955392 basic_session_run_hooks.py:541] Create CheckpointSaverHook.\n",
            "I0708 09:47:33.784286 140282142955392 monitored_session.py:240] Graph was finalized.\n",
            "2019-07-08 09:47:33.796364: I tensorflow/core/platform/profile_utils/cpu_utils.cc:94] CPU Frequency: 2200000000 Hz\n",
            "2019-07-08 09:47:33.797907: I tensorflow/compiler/xla/service/service.cc:168] XLA service 0x2a3d480 executing computations on platform Host. Devices:\n",
            "2019-07-08 09:47:33.797940: I tensorflow/compiler/xla/service/service.cc:175]   StreamExecutor device (0): <undefined>, <undefined>\n",
            "2019-07-08 09:47:33.802018: I tensorflow/stream_executor/platform/default/dso_loader.cc:42] Successfully opened dynamic library libcuda.so.1\n",
            "2019-07-08 09:47:34.010917: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:1005] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n",
            "2019-07-08 09:47:34.011505: I tensorflow/compiler/xla/service/service.cc:168] XLA service 0x2a3cd80 executing computations on platform CUDA. Devices:\n",
            "2019-07-08 09:47:34.011540: I tensorflow/compiler/xla/service/service.cc:175]   StreamExecutor device (0): Tesla T4, Compute Capability 7.5\n",
            "2019-07-08 09:47:34.011753: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:1005] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n",
            "2019-07-08 09:47:34.012146: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1640] Found device 0 with properties: \n",
            "name: Tesla T4 major: 7 minor: 5 memoryClockRate(GHz): 1.59\n",
            "pciBusID: 0000:00:04.0\n",
            "2019-07-08 09:47:34.024404: I tensorflow/stream_executor/platform/default/dso_loader.cc:42] Successfully opened dynamic library libcudart.so.10.0\n",
            "2019-07-08 09:47:34.155456: I tensorflow/stream_executor/platform/default/dso_loader.cc:42] Successfully opened dynamic library libcublas.so.10.0\n",
            "2019-07-08 09:47:34.195333: I tensorflow/stream_executor/platform/default/dso_loader.cc:42] Successfully opened dynamic library libcufft.so.10.0\n",
            "2019-07-08 09:47:34.206790: I tensorflow/stream_executor/platform/default/dso_loader.cc:42] Successfully opened dynamic library libcurand.so.10.0\n",
            "2019-07-08 09:47:34.357985: I tensorflow/stream_executor/platform/default/dso_loader.cc:42] Successfully opened dynamic library libcusolver.so.10.0\n",
            "2019-07-08 09:47:34.450735: I tensorflow/stream_executor/platform/default/dso_loader.cc:42] Successfully opened dynamic library libcusparse.so.10.0\n",
            "2019-07-08 09:47:34.719551: I tensorflow/stream_executor/platform/default/dso_loader.cc:42] Successfully opened dynamic library libcudnn.so.7\n",
            "2019-07-08 09:47:34.719801: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:1005] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n",
            "2019-07-08 09:47:34.720339: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:1005] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n",
            "2019-07-08 09:47:34.720740: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1763] Adding visible gpu devices: 0\n",
            "2019-07-08 09:47:34.722255: I tensorflow/stream_executor/platform/default/dso_loader.cc:42] Successfully opened dynamic library libcudart.so.10.0\n",
            "2019-07-08 09:47:34.724415: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1181] Device interconnect StreamExecutor with strength 1 edge matrix:\n",
            "2019-07-08 09:47:34.724444: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1187]      0 \n",
            "2019-07-08 09:47:34.724455: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1200] 0:   N \n",
            "2019-07-08 09:47:34.725927: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:1005] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n",
            "2019-07-08 09:47:34.726367: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:1005] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n",
            "2019-07-08 09:47:34.726735: W tensorflow/core/common_runtime/gpu/gpu_bfc_allocator.cc:40] Overriding allow_growth setting because the TF_FORCE_GPU_ALLOW_GROWTH environment variable is set. Original config value was 0.\n",
            "2019-07-08 09:47:34.726786: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1326] Created TensorFlow device (/job:localhost/replica:0/task:0/device:GPU:0 with 14202 MB memory) -> physical GPU (device: 0, name: Tesla T4, pci bus id: 0000:00:04.0, compute capability: 7.5)\n",
            "2019-07-08 09:47:40.291002: W tensorflow/compiler/jit/mark_for_compilation_pass.cc:1412] (One-time warning): Not using XLA:CPU for cluster because envvar TF_XLA_FLAGS=--tf_xla_cpu_global_jit was not set.  If you want XLA:CPU, either set that envvar, or use experimental_jit_scope to enable XLA:CPU.  To confirm that XLA is active, pass --vmodule=xla_compilation_cache=1 (as a proper command-line flag, not via TF_XLA_FLAGS) or set the envvar XLA_FLAGS=--xla_hlo_profile.\n",
            "I0708 09:47:40.413776 140282142955392 session_manager.py:500] Running local_init_op.\n",
            "I0708 09:47:40.667776 140282142955392 session_manager.py:502] Done running local_init_op.\n",
            "I0708 09:47:50.615127 140282142955392 basic_session_run_hooks.py:606] Saving checkpoints for 0 into training/model.ckpt.\n",
            "2019-07-08 09:47:58.269248: I tensorflow/stream_executor/platform/default/dso_loader.cc:42] Successfully opened dynamic library libcudnn.so.7\n",
            "I0708 09:48:02.352010 140282142955392 basic_session_run_hooks.py:262] loss = 43.075016, step = 0\n",
            "I0708 09:48:46.950813 140282142955392 basic_session_run_hooks.py:692] global_step/sec: 2.24218\n",
            "I0708 09:48:46.951793 140282142955392 basic_session_run_hooks.py:260] loss = 9.573874, step = 100 (44.600 sec)\n",
            "I0708 09:49:28.018048 140282142955392 basic_session_run_hooks.py:692] global_step/sec: 2.43503\n",
            "I0708 09:49:28.019094 140282142955392 basic_session_run_hooks.py:260] loss = 7.8744564, step = 200 (41.067 sec)\n",
            "I0708 09:50:09.496151 140282142955392 basic_session_run_hooks.py:692] global_step/sec: 2.41091\n",
            "I0708 09:50:09.497404 140282142955392 basic_session_run_hooks.py:260] loss = 7.6096168, step = 300 (41.478 sec)\n",
            "I0708 09:50:51.156908 140282142955392 basic_session_run_hooks.py:692] global_step/sec: 2.40034\n",
            "I0708 09:50:51.158058 140282142955392 basic_session_run_hooks.py:260] loss = 8.4028225, step = 400 (41.661 sec)\n",
            "I0708 09:51:32.568645 140282142955392 basic_session_run_hooks.py:692] global_step/sec: 2.41478\n",
            "I0708 09:51:32.569764 140282142955392 basic_session_run_hooks.py:260] loss = 7.132307, step = 500 (41.412 sec)\n",
            "I0708 09:52:13.524443 140282142955392 basic_session_run_hooks.py:692] global_step/sec: 2.44166\n",
            "I0708 09:52:13.525725 140282142955392 basic_session_run_hooks.py:260] loss = 7.3420854, step = 600 (40.956 sec)\n",
            "I0708 09:52:54.599207 140282142955392 basic_session_run_hooks.py:692] global_step/sec: 2.43458\n",
            "I0708 09:52:54.600360 140282142955392 basic_session_run_hooks.py:260] loss = 6.522118, step = 700 (41.075 sec)\n",
            "I0708 09:53:35.702450 140282142955392 basic_session_run_hooks.py:692] global_step/sec: 2.4329\n",
            "I0708 09:53:35.703399 140282142955392 basic_session_run_hooks.py:260] loss = 6.355783, step = 800 (41.103 sec)\n",
            "I0708 09:54:17.068821 140282142955392 basic_session_run_hooks.py:692] global_step/sec: 2.41742\n",
            "I0708 09:54:17.070152 140282142955392 basic_session_run_hooks.py:260] loss = 6.9180617, step = 900 (41.367 sec)\n",
            "I0708 09:54:58.057377 140282142955392 basic_session_run_hooks.py:692] global_step/sec: 2.43971\n",
            "I0708 09:54:58.058551 140282142955392 basic_session_run_hooks.py:260] loss = 6.9535923, step = 1000 (40.988 sec)\n",
            "I0708 09:55:39.353478 140282142955392 basic_session_run_hooks.py:692] global_step/sec: 2.42154\n",
            "I0708 09:55:39.354532 140282142955392 basic_session_run_hooks.py:260] loss = 6.180631, step = 1100 (41.296 sec)\n",
            "I0708 09:56:20.505147 140282142955392 basic_session_run_hooks.py:692] global_step/sec: 2.43003\n",
            "I0708 09:56:20.506230 140282142955392 basic_session_run_hooks.py:260] loss = 5.028656, step = 1200 (41.152 sec)\n",
            "I0708 09:57:01.902591 140282142955392 basic_session_run_hooks.py:692] global_step/sec: 2.41561\n",
            "I0708 09:57:01.903723 140282142955392 basic_session_run_hooks.py:260] loss = 5.662582, step = 1300 (41.397 sec)\n",
            "I0708 09:57:43.148791 140282142955392 basic_session_run_hooks.py:692] global_step/sec: 2.42447\n",
            "I0708 09:57:43.149781 140282142955392 basic_session_run_hooks.py:260] loss = 5.495525, step = 1400 (41.246 sec)\n",
            "I0708 09:57:53.018767 140282142955392 basic_session_run_hooks.py:606] Saving checkpoints for 1425 into training/model.ckpt.\n",
            "I0708 09:57:55.519181 140282142955392 estimator.py:1145] Calling model_fn.\n",
            "I0708 09:57:58.042457 140282142955392 convolutional_box_predictor.py:151] depth of additional conv before box predictor: 0\n",
            "I0708 09:57:58.080195 140282142955392 convolutional_box_predictor.py:151] depth of additional conv before box predictor: 0\n",
            "I0708 09:57:58.115199 140282142955392 convolutional_box_predictor.py:151] depth of additional conv before box predictor: 0\n",
            "I0708 09:57:58.150804 140282142955392 convolutional_box_predictor.py:151] depth of additional conv before box predictor: 0\n",
            "I0708 09:57:58.185881 140282142955392 convolutional_box_predictor.py:151] depth of additional conv before box predictor: 0\n",
            "I0708 09:57:58.221862 140282142955392 convolutional_box_predictor.py:151] depth of additional conv before box predictor: 0\n",
            "W0708 09:57:59.650736 140282142955392 deprecation.py:323] From /content/models/research/object_detection/eval_util.py:791: to_int64 (from tensorflow.python.ops.math_ops) is deprecated and will be removed in a future version.\n",
            "Instructions for updating:\n",
            "Use `tf.cast` instead.\n",
            "W0708 09:57:59.836349 140282142955392 deprecation.py:323] From /content/models/research/object_detection/utils/visualization_utils.py:492: py_func (from tensorflow.python.ops.script_ops) is deprecated and will be removed in a future version.\n",
            "Instructions for updating:\n",
            "tf.py_func is deprecated in TF V2. Instead, there are two\n",
            "    options available in V2.\n",
            "    - tf.py_function takes a python function which manipulates tf eager\n",
            "    tensors instead of numpy arrays. It's easy to convert a tf eager tensor to\n",
            "    an ndarray (just call tensor.numpy()) but having access to eager tensors\n",
            "    means `tf.py_function`s can use accelerators such as GPUs as well as\n",
            "    being differentiable using a gradient tape.\n",
            "    - tf.numpy_function maintains the semantics of the deprecated tf.py_func\n",
            "    (it is not differentiable, and manipulates numpy arrays). It drops the\n",
            "    stateful argument making all functions stateful.\n",
            "    \n",
            "W0708 09:58:00.010699 140282142955392 deprecation_wrapper.py:119] From /content/models/research/object_detection/utils/visualization_utils.py:1005: The name tf.summary.image is deprecated. Please use tf.compat.v1.summary.image instead.\n",
            "\n",
            "W0708 09:58:00.105217 140282142955392 deprecation_wrapper.py:119] From /content/models/research/object_detection/model_lib.py:473: The name tf.metrics.mean is deprecated. Please use tf.compat.v1.metrics.mean instead.\n",
            "\n",
            "I0708 09:58:00.446395 140282142955392 estimator.py:1147] Done calling model_fn.\n",
            "I0708 09:58:00.465737 140282142955392 evaluation.py:255] Starting evaluation at 2019-07-08T09:58:00Z\n",
            "I0708 09:58:00.939597 140282142955392 monitored_session.py:240] Graph was finalized.\n",
            "2019-07-08 09:58:00.940885: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:1005] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n",
            "2019-07-08 09:58:00.941229: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1640] Found device 0 with properties: \n",
            "name: Tesla T4 major: 7 minor: 5 memoryClockRate(GHz): 1.59\n",
            "pciBusID: 0000:00:04.0\n",
            "2019-07-08 09:58:00.941346: I tensorflow/stream_executor/platform/default/dso_loader.cc:42] Successfully opened dynamic library libcudart.so.10.0\n",
            "2019-07-08 09:58:00.941380: I tensorflow/stream_executor/platform/default/dso_loader.cc:42] Successfully opened dynamic library libcublas.so.10.0\n",
            "2019-07-08 09:58:00.941403: I tensorflow/stream_executor/platform/default/dso_loader.cc:42] Successfully opened dynamic library libcufft.so.10.0\n",
            "2019-07-08 09:58:00.941426: I tensorflow/stream_executor/platform/default/dso_loader.cc:42] Successfully opened dynamic library libcurand.so.10.0\n",
            "2019-07-08 09:58:00.941448: I tensorflow/stream_executor/platform/default/dso_loader.cc:42] Successfully opened dynamic library libcusolver.so.10.0\n",
            "2019-07-08 09:58:00.941469: I tensorflow/stream_executor/platform/default/dso_loader.cc:42] Successfully opened dynamic library libcusparse.so.10.0\n",
            "2019-07-08 09:58:00.941490: I tensorflow/stream_executor/platform/default/dso_loader.cc:42] Successfully opened dynamic library libcudnn.so.7\n",
            "2019-07-08 09:58:00.941591: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:1005] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n",
            "2019-07-08 09:58:00.941946: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:1005] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n",
            "2019-07-08 09:58:00.942242: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1763] Adding visible gpu devices: 0\n",
            "2019-07-08 09:58:00.942296: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1181] Device interconnect StreamExecutor with strength 1 edge matrix:\n",
            "2019-07-08 09:58:00.942310: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1187]      0 \n",
            "2019-07-08 09:58:00.942321: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1200] 0:   N \n",
            "2019-07-08 09:58:00.942552: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:1005] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n",
            "2019-07-08 09:58:00.942905: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:1005] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n",
            "2019-07-08 09:58:00.943215: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1326] Created TensorFlow device (/job:localhost/replica:0/task:0/device:GPU:0 with 14202 MB memory) -> physical GPU (device: 0, name: Tesla T4, pci bus id: 0000:00:04.0, compute capability: 7.5)\n",
            "W0708 09:58:00.943381 140282142955392 deprecation.py:323] From /usr/local/lib/python3.6/dist-packages/tensorflow/python/training/saver.py:1276: checkpoint_exists (from tensorflow.python.training.checkpoint_management) is deprecated and will be removed in a future version.\n",
            "Instructions for updating:\n",
            "Use standard file APIs to check for files with this prefix.\n",
            "I0708 09:58:00.944476 140282142955392 saver.py:1280] Restoring parameters from training/model.ckpt-1425\n",
            "I0708 09:58:01.808612 140282142955392 session_manager.py:500] Running local_init_op.\n",
            "I0708 09:58:01.912330 140282142955392 session_manager.py:502] Done running local_init_op.\n",
            "I0708 09:58:04.888234 140280368703232 coco_evaluation.py:200] Performing evaluation on 17 images.\n",
            "creating index...\n",
            "index created!\n",
            "I0708 09:58:04.888702 140280368703232 coco_tools.py:109] Loading and preparing annotation results...\n",
            "I0708 09:58:04.890017 140280368703232 coco_tools.py:131] DONE (t=0.00s)\n",
            "creating index...\n",
            "index created!\n",
            "Running per image evaluation...\n",
            "Evaluate annotation type *bbox*\n",
            "DONE (t=0.11s).\n",
            "Accumulating evaluation results...\n",
            "DONE (t=0.05s).\n",
            " Average Precision  (AP) @[ IoU=0.50:0.95 | area=   all | maxDets=100 ] = 0.111\n",
            " Average Precision  (AP) @[ IoU=0.50      | area=   all | maxDets=100 ] = 0.355\n",
            " Average Precision  (AP) @[ IoU=0.75      | area=   all | maxDets=100 ] = 0.017\n",
            " Average Precision  (AP) @[ IoU=0.50:0.95 | area= small | maxDets=100 ] = -1.000\n",
            " Average Precision  (AP) @[ IoU=0.50:0.95 | area=medium | maxDets=100 ] = 0.051\n",
            " Average Precision  (AP) @[ IoU=0.50:0.95 | area= large | maxDets=100 ] = 0.139\n",
            " Average Recall     (AR) @[ IoU=0.50:0.95 | area=   all | maxDets=  1 ] = 0.159\n",
            " Average Recall     (AR) @[ IoU=0.50:0.95 | area=   all | maxDets= 10 ] = 0.213\n",
            " Average Recall     (AR) @[ IoU=0.50:0.95 | area=   all | maxDets=100 ] = 0.228\n",
            " Average Recall     (AR) @[ IoU=0.50:0.95 | area= small | maxDets=100 ] = -1.000\n",
            " Average Recall     (AR) @[ IoU=0.50:0.95 | area=medium | maxDets=100 ] = 0.181\n",
            " Average Recall     (AR) @[ IoU=0.50:0.95 | area= large | maxDets=100 ] = 0.253\n",
            "I0708 09:58:05.378006 140282142955392 evaluation.py:275] Finished evaluation at 2019-07-08-09:58:05\n",
            "I0708 09:58:05.378315 140282142955392 estimator.py:2039] Saving dict for global step 1425: DetectionBoxes_Precision/mAP = 0.11053892, DetectionBoxes_Precision/mAP (large) = 0.13860258, DetectionBoxes_Precision/mAP (medium) = 0.05086921, DetectionBoxes_Precision/mAP (small) = -1.0, DetectionBoxes_Precision/mAP@.50IOU = 0.35534558, DetectionBoxes_Precision/mAP@.75IOU = 0.01701595, DetectionBoxes_Recall/AR@1 = 0.15888889, DetectionBoxes_Recall/AR@10 = 0.21333334, DetectionBoxes_Recall/AR@100 = 0.22777778, DetectionBoxes_Recall/AR@100 (large) = 0.25333333, DetectionBoxes_Recall/AR@100 (medium) = 0.18125, DetectionBoxes_Recall/AR@100 (small) = -1.0, Loss/classification_loss = 8.449875, Loss/localization_loss = 2.1629207, Loss/regularization_loss = 0.2553888, Loss/total_loss = 10.868184, global_step = 1425, learning_rate = 0.004, loss = 10.868184\n",
            "I0708 09:58:06.215497 140282142955392 estimator.py:2099] Saving 'checkpoint_path' summary for global step 1425: training/model.ckpt-1425\n",
            "I0708 09:58:37.552396 140282142955392 basic_session_run_hooks.py:692] global_step/sec: 1.83811\n",
            "I0708 09:58:37.553487 140282142955392 basic_session_run_hooks.py:260] loss = 5.2696733, step = 1500 (54.404 sec)\n",
            "I0708 09:59:18.439210 140282142955392 basic_session_run_hooks.py:692] global_step/sec: 2.44578\n",
            "I0708 09:59:18.440484 140282142955392 basic_session_run_hooks.py:260] loss = 4.946514, step = 1600 (40.887 sec)\n",
            "I0708 09:59:59.307778 140282142955392 basic_session_run_hooks.py:692] global_step/sec: 2.44687\n",
            "I0708 09:59:59.308879 140282142955392 basic_session_run_hooks.py:260] loss = 5.392394, step = 1700 (40.868 sec)\n",
            "I0708 10:00:40.116839 140282142955392 basic_session_run_hooks.py:692] global_step/sec: 2.45043\n",
            "I0708 10:00:40.118015 140282142955392 basic_session_run_hooks.py:260] loss = 5.2724824, step = 1800 (40.809 sec)\n",
            "I0708 10:01:20.872653 140282142955392 basic_session_run_hooks.py:692] global_step/sec: 2.45364\n",
            "I0708 10:01:20.873704 140282142955392 basic_session_run_hooks.py:260] loss = 4.077113, step = 1900 (40.756 sec)\n",
            "I0708 10:02:01.664379 140282142955392 basic_session_run_hooks.py:692] global_step/sec: 2.45148\n",
            "I0708 10:02:01.665557 140282142955392 basic_session_run_hooks.py:260] loss = 5.906904, step = 2000 (40.792 sec)\n",
            "I0708 10:02:42.524838 140282142955392 basic_session_run_hooks.py:692] global_step/sec: 2.44735\n",
            "I0708 10:02:42.526326 140282142955392 basic_session_run_hooks.py:260] loss = 4.4996333, step = 2100 (40.861 sec)\n",
            "I0708 10:03:23.212643 140282142955392 basic_session_run_hooks.py:692] global_step/sec: 2.45774\n",
            "I0708 10:03:23.213545 140282142955392 basic_session_run_hooks.py:260] loss = 4.706048, step = 2200 (40.687 sec)\n",
            "I0708 10:04:03.944842 140282142955392 basic_session_run_hooks.py:692] global_step/sec: 2.45506\n",
            "I0708 10:04:03.945801 140282142955392 basic_session_run_hooks.py:260] loss = 4.343623, step = 2300 (40.732 sec)\n",
            "I0708 10:04:44.805645 140282142955392 basic_session_run_hooks.py:692] global_step/sec: 2.44733\n",
            "I0708 10:04:44.806549 140282142955392 basic_session_run_hooks.py:260] loss = 4.986026, step = 2400 (40.861 sec)\n",
            "I0708 10:05:25.300477 140282142955392 basic_session_run_hooks.py:692] global_step/sec: 2.46945\n",
            "I0708 10:05:25.301523 140282142955392 basic_session_run_hooks.py:260] loss = 4.3616548, step = 2500 (40.495 sec)\n",
            "I0708 10:06:06.011158 140282142955392 basic_session_run_hooks.py:692] global_step/sec: 2.45636\n",
            "I0708 10:06:06.012623 140282142955392 basic_session_run_hooks.py:260] loss = 3.884283, step = 2600 (40.711 sec)\n",
            "I0708 10:06:47.021360 140282142955392 basic_session_run_hooks.py:692] global_step/sec: 2.43842\n",
            "I0708 10:06:47.022378 140282142955392 basic_session_run_hooks.py:260] loss = 3.4925673, step = 2700 (41.010 sec)\n",
            "I0708 10:07:27.737488 140282142955392 basic_session_run_hooks.py:692] global_step/sec: 2.45603\n",
            "I0708 10:07:27.738661 140282142955392 basic_session_run_hooks.py:260] loss = 3.975472, step = 2800 (40.716 sec)\n",
            "I0708 10:07:53.371615 140282142955392 basic_session_run_hooks.py:606] Saving checkpoints for 2864 into training/model.ckpt.\n",
            "I0708 10:07:55.461178 140282142955392 estimator.py:1145] Calling model_fn.\n",
            "I0708 10:07:58.458369 140282142955392 convolutional_box_predictor.py:151] depth of additional conv before box predictor: 0\n",
            "I0708 10:07:58.494075 140282142955392 convolutional_box_predictor.py:151] depth of additional conv before box predictor: 0\n",
            "I0708 10:07:58.528422 140282142955392 convolutional_box_predictor.py:151] depth of additional conv before box predictor: 0\n",
            "I0708 10:07:58.564109 140282142955392 convolutional_box_predictor.py:151] depth of additional conv before box predictor: 0\n",
            "I0708 10:07:58.600622 140282142955392 convolutional_box_predictor.py:151] depth of additional conv before box predictor: 0\n",
            "I0708 10:07:58.635937 140282142955392 convolutional_box_predictor.py:151] depth of additional conv before box predictor: 0\n",
            "I0708 10:08:00.438714 140282142955392 estimator.py:1147] Done calling model_fn.\n",
            "I0708 10:08:00.456826 140282142955392 evaluation.py:255] Starting evaluation at 2019-07-08T10:08:00Z\n",
            "I0708 10:08:00.919577 140282142955392 monitored_session.py:240] Graph was finalized.\n",
            "2019-07-08 10:08:00.920291: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:1005] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n",
            "2019-07-08 10:08:00.920789: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1640] Found device 0 with properties: \n",
            "name: Tesla T4 major: 7 minor: 5 memoryClockRate(GHz): 1.59\n",
            "pciBusID: 0000:00:04.0\n",
            "2019-07-08 10:08:00.920921: I tensorflow/stream_executor/platform/default/dso_loader.cc:42] Successfully opened dynamic library libcudart.so.10.0\n",
            "2019-07-08 10:08:00.920962: I tensorflow/stream_executor/platform/default/dso_loader.cc:42] Successfully opened dynamic library libcublas.so.10.0\n",
            "2019-07-08 10:08:00.920988: I tensorflow/stream_executor/platform/default/dso_loader.cc:42] Successfully opened dynamic library libcufft.so.10.0\n",
            "2019-07-08 10:08:00.921016: I tensorflow/stream_executor/platform/default/dso_loader.cc:42] Successfully opened dynamic library libcurand.so.10.0\n",
            "2019-07-08 10:08:00.921042: I tensorflow/stream_executor/platform/default/dso_loader.cc:42] Successfully opened dynamic library libcusolver.so.10.0\n",
            "2019-07-08 10:08:00.921065: I tensorflow/stream_executor/platform/default/dso_loader.cc:42] Successfully opened dynamic library libcusparse.so.10.0\n",
            "2019-07-08 10:08:00.921090: I tensorflow/stream_executor/platform/default/dso_loader.cc:42] Successfully opened dynamic library libcudnn.so.7\n",
            "2019-07-08 10:08:00.921210: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:1005] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n",
            "2019-07-08 10:08:00.921755: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:1005] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n",
            "2019-07-08 10:08:00.922176: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1763] Adding visible gpu devices: 0\n",
            "2019-07-08 10:08:00.922252: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1181] Device interconnect StreamExecutor with strength 1 edge matrix:\n",
            "2019-07-08 10:08:00.922283: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1187]      0 \n",
            "2019-07-08 10:08:00.922294: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1200] 0:   N \n",
            "2019-07-08 10:08:00.922638: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:1005] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n",
            "2019-07-08 10:08:00.923195: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:1005] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n",
            "2019-07-08 10:08:00.923596: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1326] Created TensorFlow device (/job:localhost/replica:0/task:0/device:GPU:0 with 14202 MB memory) -> physical GPU (device: 0, name: Tesla T4, pci bus id: 0000:00:04.0, compute capability: 7.5)\n",
            "I0708 10:08:00.924584 140282142955392 saver.py:1280] Restoring parameters from training/model.ckpt-2864\n",
            "I0708 10:08:01.789029 140282142955392 session_manager.py:500] Running local_init_op.\n",
            "I0708 10:08:01.894341 140282142955392 session_manager.py:502] Done running local_init_op.\n",
            "I0708 10:08:04.410392 140280360310528 coco_evaluation.py:200] Performing evaluation on 17 images.\n",
            "creating index...\n",
            "index created!\n",
            "I0708 10:08:04.410909 140280360310528 coco_tools.py:109] Loading and preparing annotation results...\n",
            "I0708 10:08:04.412412 140280360310528 coco_tools.py:131] DONE (t=0.00s)\n",
            "creating index...\n",
            "index created!\n",
            "Running per image evaluation...\n",
            "Evaluate annotation type *bbox*\n",
            "DONE (t=0.07s).\n",
            "Accumulating evaluation results...\n",
            "DONE (t=0.04s).\n",
            " Average Precision  (AP) @[ IoU=0.50:0.95 | area=   all | maxDets=100 ] = 0.136\n",
            " Average Precision  (AP) @[ IoU=0.50      | area=   all | maxDets=100 ] = 0.532\n",
            " Average Precision  (AP) @[ IoU=0.75      | area=   all | maxDets=100 ] = 0.075\n",
            " Average Precision  (AP) @[ IoU=0.50:0.95 | area= small | maxDets=100 ] = -1.000\n",
            " Average Precision  (AP) @[ IoU=0.50:0.95 | area=medium | maxDets=100 ] = 0.068\n",
            " Average Precision  (AP) @[ IoU=0.50:0.95 | area= large | maxDets=100 ] = 0.146\n",
            " Average Recall     (AR) @[ IoU=0.50:0.95 | area=   all | maxDets=  1 ] = 0.192\n",
            " Average Recall     (AR) @[ IoU=0.50:0.95 | area=   all | maxDets= 10 ] = 0.242\n",
            " Average Recall     (AR) @[ IoU=0.50:0.95 | area=   all | maxDets=100 ] = 0.242\n",
            " Average Recall     (AR) @[ IoU=0.50:0.95 | area= small | maxDets=100 ] = -1.000\n",
            " Average Recall     (AR) @[ IoU=0.50:0.95 | area=medium | maxDets=100 ] = 0.225\n",
            " Average Recall     (AR) @[ IoU=0.50:0.95 | area= large | maxDets=100 ] = 0.225\n",
            "I0708 10:08:04.844171 140282142955392 evaluation.py:275] Finished evaluation at 2019-07-08-10:08:04\n",
            "I0708 10:08:04.844442 140282142955392 estimator.py:2039] Saving dict for global step 2864: DetectionBoxes_Precision/mAP = 0.13553776, DetectionBoxes_Precision/mAP (large) = 0.14571647, DetectionBoxes_Precision/mAP (medium) = 0.068389475, DetectionBoxes_Precision/mAP (small) = -1.0, DetectionBoxes_Precision/mAP@.50IOU = 0.53205967, DetectionBoxes_Precision/mAP@.75IOU = 0.075247526, DetectionBoxes_Recall/AR@1 = 0.19222222, DetectionBoxes_Recall/AR@10 = 0.24222222, DetectionBoxes_Recall/AR@100 = 0.24222222, DetectionBoxes_Recall/AR@100 (large) = 0.22533333, DetectionBoxes_Recall/AR@100 (medium) = 0.225, DetectionBoxes_Recall/AR@100 (small) = -1.0, Loss/classification_loss = 9.048559, Loss/localization_loss = 2.3367426, Loss/regularization_loss = 0.26182672, Loss/total_loss = 11.647129, global_step = 2864, learning_rate = 0.004, loss = 11.647129\n",
            "I0708 10:08:04.849549 140282142955392 estimator.py:2099] Saving 'checkpoint_path' summary for global step 2864: training/model.ckpt-2864\n",
            "I0708 10:08:19.979992 140282142955392 basic_session_run_hooks.py:692] global_step/sec: 1.91415\n",
            "I0708 10:08:19.980843 140282142955392 basic_session_run_hooks.py:260] loss = 3.825924, step = 2900 (52.242 sec)\n",
            "I0708 10:09:00.597471 140282142955392 basic_session_run_hooks.py:692] global_step/sec: 2.462\n",
            "I0708 10:09:00.598649 140282142955392 basic_session_run_hooks.py:260] loss = 4.9845657, step = 3000 (40.618 sec)\n",
            "I0708 10:09:41.277818 140282142955392 basic_session_run_hooks.py:692] global_step/sec: 2.45819\n",
            "I0708 10:09:41.278942 140282142955392 basic_session_run_hooks.py:260] loss = 3.2012038, step = 3100 (40.680 sec)\n",
            "I0708 10:10:22.087882 140282142955392 basic_session_run_hooks.py:692] global_step/sec: 2.45037\n",
            "I0708 10:10:22.089025 140282142955392 basic_session_run_hooks.py:260] loss = 4.196837, step = 3200 (40.810 sec)\n",
            "I0708 10:11:02.578211 140282142955392 basic_session_run_hooks.py:692] global_step/sec: 2.46972\n",
            "I0708 10:11:02.579308 140282142955392 basic_session_run_hooks.py:260] loss = 4.757197, step = 3300 (40.490 sec)\n",
            "I0708 10:11:43.472318 140282142955392 basic_session_run_hooks.py:692] global_step/sec: 2.44534\n",
            "I0708 10:11:43.473309 140282142955392 basic_session_run_hooks.py:260] loss = 3.351937, step = 3400 (40.894 sec)\n",
            "I0708 10:12:24.104747 140282142955392 basic_session_run_hooks.py:692] global_step/sec: 2.46108\n",
            "I0708 10:12:24.105691 140282142955392 basic_session_run_hooks.py:260] loss = 3.338145, step = 3500 (40.632 sec)\n",
            "I0708 10:13:04.835246 140282142955392 basic_session_run_hooks.py:692] global_step/sec: 2.45516\n",
            "I0708 10:13:04.836497 140282142955392 basic_session_run_hooks.py:260] loss = 4.256063, step = 3600 (40.731 sec)\n",
            "I0708 10:13:45.560078 140282142955392 basic_session_run_hooks.py:692] global_step/sec: 2.4555\n",
            "I0708 10:13:45.561380 140282142955392 basic_session_run_hooks.py:260] loss = 2.9849942, step = 3700 (40.725 sec)\n",
            "I0708 10:14:26.450664 140282142955392 basic_session_run_hooks.py:692] global_step/sec: 2.44555\n",
            "I0708 10:14:26.451572 140282142955392 basic_session_run_hooks.py:260] loss = 3.56871, step = 3800 (40.890 sec)\n",
            "I0708 10:15:07.157182 140282142955392 basic_session_run_hooks.py:692] global_step/sec: 2.45661\n",
            "I0708 10:15:07.158257 140282142955392 basic_session_run_hooks.py:260] loss = 4.8623724, step = 3900 (40.707 sec)\n",
            "I0708 10:15:47.830013 140282142955392 basic_session_run_hooks.py:692] global_step/sec: 2.45864\n",
            "I0708 10:15:47.831139 140282142955392 basic_session_run_hooks.py:260] loss = 3.8181927, step = 4000 (40.673 sec)\n",
            "I0708 10:16:28.373322 140282142955392 basic_session_run_hooks.py:692] global_step/sec: 2.4665\n",
            "I0708 10:16:28.374534 140282142955392 basic_session_run_hooks.py:260] loss = 3.994551, step = 4100 (40.543 sec)\n",
            "I0708 10:17:08.981950 140282142955392 basic_session_run_hooks.py:692] global_step/sec: 2.46253\n",
            "I0708 10:17:08.983095 140282142955392 basic_session_run_hooks.py:260] loss = 3.3871474, step = 4200 (40.609 sec)\n",
            "I0708 10:17:49.746626 140282142955392 basic_session_run_hooks.py:692] global_step/sec: 2.45311\n",
            "I0708 10:17:49.747775 140282142955392 basic_session_run_hooks.py:260] loss = 4.3133054, step = 4300 (40.765 sec)\n",
            "I0708 10:17:53.426420 140282142955392 basic_session_run_hooks.py:606] Saving checkpoints for 4310 into training/model.ckpt.\n",
            "I0708 10:17:55.611965 140282142955392 estimator.py:1145] Calling model_fn.\n",
            "I0708 10:17:58.585318 140282142955392 convolutional_box_predictor.py:151] depth of additional conv before box predictor: 0\n",
            "I0708 10:17:58.626055 140282142955392 convolutional_box_predictor.py:151] depth of additional conv before box predictor: 0\n",
            "I0708 10:17:58.666304 140282142955392 convolutional_box_predictor.py:151] depth of additional conv before box predictor: 0\n",
            "I0708 10:17:58.702156 140282142955392 convolutional_box_predictor.py:151] depth of additional conv before box predictor: 0\n",
            "I0708 10:17:58.736630 140282142955392 convolutional_box_predictor.py:151] depth of additional conv before box predictor: 0\n",
            "I0708 10:17:58.772994 140282142955392 convolutional_box_predictor.py:151] depth of additional conv before box predictor: 0\n",
            "I0708 10:18:00.909464 140282142955392 estimator.py:1147] Done calling model_fn.\n",
            "I0708 10:18:00.928286 140282142955392 evaluation.py:255] Starting evaluation at 2019-07-08T10:18:00Z\n",
            "I0708 10:18:01.393945 140282142955392 monitored_session.py:240] Graph was finalized.\n",
            "2019-07-08 10:18:01.394636: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:1005] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n",
            "2019-07-08 10:18:01.395155: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1640] Found device 0 with properties: \n",
            "name: Tesla T4 major: 7 minor: 5 memoryClockRate(GHz): 1.59\n",
            "pciBusID: 0000:00:04.0\n",
            "2019-07-08 10:18:01.395361: I tensorflow/stream_executor/platform/default/dso_loader.cc:42] Successfully opened dynamic library libcudart.so.10.0\n",
            "2019-07-08 10:18:01.395396: I tensorflow/stream_executor/platform/default/dso_loader.cc:42] Successfully opened dynamic library libcublas.so.10.0\n",
            "2019-07-08 10:18:01.395426: I tensorflow/stream_executor/platform/default/dso_loader.cc:42] Successfully opened dynamic library libcufft.so.10.0\n",
            "2019-07-08 10:18:01.395451: I tensorflow/stream_executor/platform/default/dso_loader.cc:42] Successfully opened dynamic library libcurand.so.10.0\n",
            "2019-07-08 10:18:01.395473: I tensorflow/stream_executor/platform/default/dso_loader.cc:42] Successfully opened dynamic library libcusolver.so.10.0\n",
            "2019-07-08 10:18:01.395497: I tensorflow/stream_executor/platform/default/dso_loader.cc:42] Successfully opened dynamic library libcusparse.so.10.0\n",
            "2019-07-08 10:18:01.395529: I tensorflow/stream_executor/platform/default/dso_loader.cc:42] Successfully opened dynamic library libcudnn.so.7\n",
            "2019-07-08 10:18:01.395656: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:1005] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n",
            "2019-07-08 10:18:01.396210: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:1005] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n",
            "2019-07-08 10:18:01.396654: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1763] Adding visible gpu devices: 0\n",
            "2019-07-08 10:18:01.396722: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1181] Device interconnect StreamExecutor with strength 1 edge matrix:\n",
            "2019-07-08 10:18:01.396740: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1187]      0 \n",
            "2019-07-08 10:18:01.396753: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1200] 0:   N \n",
            "2019-07-08 10:18:01.397087: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:1005] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n",
            "2019-07-08 10:18:01.397660: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:1005] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n",
            "2019-07-08 10:18:01.398102: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1326] Created TensorFlow device (/job:localhost/replica:0/task:0/device:GPU:0 with 14202 MB memory) -> physical GPU (device: 0, name: Tesla T4, pci bus id: 0000:00:04.0, compute capability: 7.5)\n",
            "I0708 10:18:01.399524 140282142955392 saver.py:1280] Restoring parameters from training/model.ckpt-4310\n",
            "I0708 10:18:02.274911 140282142955392 session_manager.py:500] Running local_init_op.\n",
            "I0708 10:18:02.383791 140282142955392 session_manager.py:502] Done running local_init_op.\n",
            "I0708 10:18:04.960231 140280368703232 coco_evaluation.py:200] Performing evaluation on 17 images.\n",
            "creating index...\n",
            "index created!\n",
            "I0708 10:18:04.960680 140280368703232 coco_tools.py:109] Loading and preparing annotation results...\n",
            "I0708 10:18:04.962063 140280368703232 coco_tools.py:131] DONE (t=0.00s)\n",
            "creating index...\n",
            "index created!\n",
            "Running per image evaluation...\n",
            "Evaluate annotation type *bbox*\n",
            "DONE (t=0.08s).\n",
            "Accumulating evaluation results...\n",
            "DONE (t=0.04s).\n",
            " Average Precision  (AP) @[ IoU=0.50:0.95 | area=   all | maxDets=100 ] = 0.118\n",
            " Average Precision  (AP) @[ IoU=0.50      | area=   all | maxDets=100 ] = 0.280\n",
            " Average Precision  (AP) @[ IoU=0.75      | area=   all | maxDets=100 ] = 0.083\n",
            " Average Precision  (AP) @[ IoU=0.50:0.95 | area= small | maxDets=100 ] = -1.000\n",
            " Average Precision  (AP) @[ IoU=0.50:0.95 | area=medium | maxDets=100 ] = 0.090\n",
            " Average Precision  (AP) @[ IoU=0.50:0.95 | area= large | maxDets=100 ] = 0.137\n",
            " Average Recall     (AR) @[ IoU=0.50:0.95 | area=   all | maxDets=  1 ] = 0.133\n",
            " Average Recall     (AR) @[ IoU=0.50:0.95 | area=   all | maxDets= 10 ] = 0.289\n",
            " Average Recall     (AR) @[ IoU=0.50:0.95 | area=   all | maxDets=100 ] = 0.289\n",
            " Average Recall     (AR) @[ IoU=0.50:0.95 | area= small | maxDets=100 ] = -1.000\n",
            " Average Recall     (AR) @[ IoU=0.50:0.95 | area=medium | maxDets=100 ] = 0.219\n",
            " Average Recall     (AR) @[ IoU=0.50:0.95 | area= large | maxDets=100 ] = 0.289\n",
            "I0708 10:18:05.407747 140282142955392 evaluation.py:275] Finished evaluation at 2019-07-08-10:18:05\n",
            "I0708 10:18:05.408041 140282142955392 estimator.py:2039] Saving dict for global step 4310: DetectionBoxes_Precision/mAP = 0.11848773, DetectionBoxes_Precision/mAP (large) = 0.13740678, DetectionBoxes_Precision/mAP (medium) = 0.090230234, DetectionBoxes_Precision/mAP (small) = -1.0, DetectionBoxes_Precision/mAP@.50IOU = 0.2802163, DetectionBoxes_Precision/mAP@.75IOU = 0.08316832, DetectionBoxes_Recall/AR@1 = 0.13333334, DetectionBoxes_Recall/AR@10 = 0.2888889, DetectionBoxes_Recall/AR@100 = 0.2888889, DetectionBoxes_Recall/AR@100 (large) = 0.28933334, DetectionBoxes_Recall/AR@100 (medium) = 0.21875, DetectionBoxes_Recall/AR@100 (small) = -1.0, Loss/classification_loss = 10.904452, Loss/localization_loss = 2.279824, Loss/regularization_loss = 0.26795718, Loss/total_loss = 13.452232, global_step = 4310, learning_rate = 0.004, loss = 13.452232\n",
            "I0708 10:18:05.411658 140282142955392 estimator.py:2099] Saving 'checkpoint_path' summary for global step 4310: training/model.ckpt-4310\n",
            "I0708 10:18:42.916845 140282142955392 basic_session_run_hooks.py:692] global_step/sec: 1.88075\n",
            "I0708 10:18:42.917749 140282142955392 basic_session_run_hooks.py:260] loss = 3.4555836, step = 4400 (53.170 sec)\n",
            "I0708 10:19:23.749407 140282142955392 basic_session_run_hooks.py:692] global_step/sec: 2.44903\n",
            "I0708 10:19:23.750576 140282142955392 basic_session_run_hooks.py:260] loss = 3.3153467, step = 4500 (40.833 sec)\n",
            "I0708 10:20:04.796327 140282142955392 basic_session_run_hooks.py:692] global_step/sec: 2.43624\n",
            "I0708 10:20:04.797441 140282142955392 basic_session_run_hooks.py:260] loss = 2.8069556, step = 4600 (41.047 sec)\n",
            "I0708 10:20:45.550992 140282142955392 basic_session_run_hooks.py:692] global_step/sec: 2.45371\n",
            "I0708 10:20:45.551990 140282142955392 basic_session_run_hooks.py:260] loss = 2.7243526, step = 4700 (40.755 sec)\n",
            "I0708 10:21:26.396332 140282142955392 basic_session_run_hooks.py:692] global_step/sec: 2.44827\n",
            "I0708 10:21:26.398051 140282142955392 basic_session_run_hooks.py:260] loss = 3.5842505, step = 4800 (40.846 sec)\n",
            "I0708 10:22:07.093615 140282142955392 basic_session_run_hooks.py:692] global_step/sec: 2.45716\n",
            "I0708 10:22:07.094779 140282142955392 basic_session_run_hooks.py:260] loss = 3.4394405, step = 4900 (40.697 sec)\n",
            "I0708 10:22:47.942677 140282142955392 basic_session_run_hooks.py:692] global_step/sec: 2.44804\n",
            "I0708 10:22:47.943929 140282142955392 basic_session_run_hooks.py:260] loss = 2.7774434, step = 5000 (40.849 sec)\n",
            "I0708 10:23:29.027898 140282142955392 basic_session_run_hooks.py:692] global_step/sec: 2.43396\n",
            "I0708 10:23:29.029095 140282142955392 basic_session_run_hooks.py:260] loss = 2.8188133, step = 5100 (41.085 sec)\n",
            "I0708 10:24:09.675923 140282142955392 basic_session_run_hooks.py:692] global_step/sec: 2.46014\n",
            "I0708 10:24:09.676889 140282142955392 basic_session_run_hooks.py:260] loss = 3.307611, step = 5200 (40.648 sec)\n",
            "I0708 10:24:50.413508 140282142955392 basic_session_run_hooks.py:692] global_step/sec: 2.45474\n",
            "I0708 10:24:50.414591 140282142955392 basic_session_run_hooks.py:260] loss = 2.8301208, step = 5300 (40.738 sec)\n",
            "I0708 10:25:30.875009 140282142955392 basic_session_run_hooks.py:692] global_step/sec: 2.47149\n",
            "I0708 10:25:30.876129 140282142955392 basic_session_run_hooks.py:260] loss = 3.6296706, step = 5400 (40.462 sec)\n",
            "I0708 10:26:11.507603 140282142955392 basic_session_run_hooks.py:692] global_step/sec: 2.46108\n",
            "I0708 10:26:11.508614 140282142955392 basic_session_run_hooks.py:260] loss = 2.62779, step = 5500 (40.632 sec)\n",
            "I0708 10:26:52.229190 140282142955392 basic_session_run_hooks.py:692] global_step/sec: 2.4557\n",
            "I0708 10:26:52.230235 140282142955392 basic_session_run_hooks.py:260] loss = 2.2854257, step = 5600 (40.722 sec)\n",
            "I0708 10:27:32.972507 140282142955392 basic_session_run_hooks.py:692] global_step/sec: 2.45439\n",
            "I0708 10:27:32.973687 140282142955392 basic_session_run_hooks.py:260] loss = 2.3088033, step = 5700 (40.743 sec)\n",
            "I0708 10:27:53.681319 140282142955392 basic_session_run_hooks.py:606] Saving checkpoints for 5752 into training/model.ckpt.\n",
            "I0708 10:27:55.813385 140282142955392 estimator.py:1145] Calling model_fn.\n",
            "I0708 10:27:58.259989 140282142955392 convolutional_box_predictor.py:151] depth of additional conv before box predictor: 0\n",
            "I0708 10:27:58.295378 140282142955392 convolutional_box_predictor.py:151] depth of additional conv before box predictor: 0\n",
            "I0708 10:27:58.329635 140282142955392 convolutional_box_predictor.py:151] depth of additional conv before box predictor: 0\n",
            "I0708 10:27:58.364022 140282142955392 convolutional_box_predictor.py:151] depth of additional conv before box predictor: 0\n",
            "I0708 10:27:58.398185 140282142955392 convolutional_box_predictor.py:151] depth of additional conv before box predictor: 0\n",
            "I0708 10:27:58.432677 140282142955392 convolutional_box_predictor.py:151] depth of additional conv before box predictor: 0\n",
            "I0708 10:28:00.784248 140282142955392 estimator.py:1147] Done calling model_fn.\n",
            "I0708 10:28:00.805151 140282142955392 evaluation.py:255] Starting evaluation at 2019-07-08T10:28:00Z\n",
            "I0708 10:28:01.290676 140282142955392 monitored_session.py:240] Graph was finalized.\n",
            "2019-07-08 10:28:01.291316: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:1005] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n",
            "2019-07-08 10:28:01.291684: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1640] Found device 0 with properties: \n",
            "name: Tesla T4 major: 7 minor: 5 memoryClockRate(GHz): 1.59\n",
            "pciBusID: 0000:00:04.0\n",
            "2019-07-08 10:28:01.291787: I tensorflow/stream_executor/platform/default/dso_loader.cc:42] Successfully opened dynamic library libcudart.so.10.0\n",
            "2019-07-08 10:28:01.291812: I tensorflow/stream_executor/platform/default/dso_loader.cc:42] Successfully opened dynamic library libcublas.so.10.0\n",
            "2019-07-08 10:28:01.291833: I tensorflow/stream_executor/platform/default/dso_loader.cc:42] Successfully opened dynamic library libcufft.so.10.0\n",
            "2019-07-08 10:28:01.291855: I tensorflow/stream_executor/platform/default/dso_loader.cc:42] Successfully opened dynamic library libcurand.so.10.0\n",
            "2019-07-08 10:28:01.291889: I tensorflow/stream_executor/platform/default/dso_loader.cc:42] Successfully opened dynamic library libcusolver.so.10.0\n",
            "2019-07-08 10:28:01.291911: I tensorflow/stream_executor/platform/default/dso_loader.cc:42] Successfully opened dynamic library libcusparse.so.10.0\n",
            "2019-07-08 10:28:01.291931: I tensorflow/stream_executor/platform/default/dso_loader.cc:42] Successfully opened dynamic library libcudnn.so.7\n",
            "2019-07-08 10:28:01.292021: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:1005] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n",
            "2019-07-08 10:28:01.292397: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:1005] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n",
            "2019-07-08 10:28:01.292744: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1763] Adding visible gpu devices: 0\n",
            "2019-07-08 10:28:01.292792: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1181] Device interconnect StreamExecutor with strength 1 edge matrix:\n",
            "2019-07-08 10:28:01.292812: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1187]      0 \n",
            "2019-07-08 10:28:01.292824: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1200] 0:   N \n",
            "2019-07-08 10:28:01.293084: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:1005] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n",
            "2019-07-08 10:28:01.293481: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:1005] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n",
            "2019-07-08 10:28:01.293809: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1326] Created TensorFlow device (/job:localhost/replica:0/task:0/device:GPU:0 with 14202 MB memory) -> physical GPU (device: 0, name: Tesla T4, pci bus id: 0000:00:04.0, compute capability: 7.5)\n",
            "I0708 10:28:01.294978 140282142955392 saver.py:1280] Restoring parameters from training/model.ckpt-5752\n",
            "I0708 10:28:02.205297 140282142955392 session_manager.py:500] Running local_init_op.\n",
            "I0708 10:28:02.322264 140282142955392 session_manager.py:502] Done running local_init_op.\n",
            "I0708 10:28:04.903882 140280368703232 coco_evaluation.py:200] Performing evaluation on 17 images.\n",
            "creating index...\n",
            "index created!\n",
            "I0708 10:28:04.904739 140280368703232 coco_tools.py:109] Loading and preparing annotation results...\n",
            "I0708 10:28:04.906112 140280368703232 coco_tools.py:131] DONE (t=0.00s)\n",
            "creating index...\n",
            "index created!\n",
            "Running per image evaluation...\n",
            "Evaluate annotation type *bbox*\n",
            "DONE (t=0.10s).\n",
            "Accumulating evaluation results...\n",
            "DONE (t=0.05s).\n",
            " Average Precision  (AP) @[ IoU=0.50:0.95 | area=   all | maxDets=100 ] = 0.180\n",
            " Average Precision  (AP) @[ IoU=0.50      | area=   all | maxDets=100 ] = 0.404\n",
            " Average Precision  (AP) @[ IoU=0.75      | area=   all | maxDets=100 ] = 0.164\n",
            " Average Precision  (AP) @[ IoU=0.50:0.95 | area= small | maxDets=100 ] = -1.000\n",
            " Average Precision  (AP) @[ IoU=0.50:0.95 | area=medium | maxDets=100 ] = 0.131\n",
            " Average Precision  (AP) @[ IoU=0.50:0.95 | area= large | maxDets=100 ] = 0.199\n",
            " Average Recall     (AR) @[ IoU=0.50:0.95 | area=   all | maxDets=  1 ] = 0.197\n",
            " Average Recall     (AR) @[ IoU=0.50:0.95 | area=   all | maxDets= 10 ] = 0.359\n",
            " Average Recall     (AR) @[ IoU=0.50:0.95 | area=   all | maxDets=100 ] = 0.390\n",
            " Average Recall     (AR) @[ IoU=0.50:0.95 | area= small | maxDets=100 ] = -1.000\n",
            " Average Recall     (AR) @[ IoU=0.50:0.95 | area=medium | maxDets=100 ] = 0.525\n",
            " Average Recall     (AR) @[ IoU=0.50:0.95 | area= large | maxDets=100 ] = 0.347\n",
            "I0708 10:28:05.386874 140282142955392 evaluation.py:275] Finished evaluation at 2019-07-08-10:28:05\n",
            "I0708 10:28:05.387135 140282142955392 estimator.py:2039] Saving dict for global step 5752: DetectionBoxes_Precision/mAP = 0.1800848, DetectionBoxes_Precision/mAP (large) = 0.19902675, DetectionBoxes_Precision/mAP (medium) = 0.13065799, DetectionBoxes_Precision/mAP (small) = -1.0, DetectionBoxes_Precision/mAP@.50IOU = 0.40437475, DetectionBoxes_Precision/mAP@.75IOU = 0.16443945, DetectionBoxes_Recall/AR@1 = 0.19666667, DetectionBoxes_Recall/AR@10 = 0.3588889, DetectionBoxes_Recall/AR@100 = 0.39, DetectionBoxes_Recall/AR@100 (large) = 0.34733334, DetectionBoxes_Recall/AR@100 (medium) = 0.525, DetectionBoxes_Recall/AR@100 (small) = -1.0, Loss/classification_loss = 9.802695, Loss/localization_loss = 1.767174, Loss/regularization_loss = 0.27352995, Loss/total_loss = 11.843399, global_step = 5752, learning_rate = 0.004, loss = 11.843399\n",
            "I0708 10:28:05.390852 140282142955392 estimator.py:2099] Saving 'checkpoint_path' summary for global step 5752: training/model.ckpt-5752\n",
            "I0708 10:28:25.381496 140282142955392 basic_session_run_hooks.py:692] global_step/sec: 1.90807\n",
            "I0708 10:28:25.382552 140282142955392 basic_session_run_hooks.py:260] loss = 3.3697572, step = 5800 (52.409 sec)\n",
            "I0708 10:29:06.226165 140282142955392 basic_session_run_hooks.py:692] global_step/sec: 2.4483\n",
            "I0708 10:29:06.227117 140282142955392 basic_session_run_hooks.py:260] loss = 4.0069404, step = 5900 (40.845 sec)\n",
            "I0708 10:29:46.666198 140282142955392 basic_session_run_hooks.py:692] global_step/sec: 2.4728\n",
            "I0708 10:29:46.667537 140282142955392 basic_session_run_hooks.py:260] loss = 3.068903, step = 6000 (40.440 sec)\n",
            "I0708 10:30:27.482164 140282142955392 basic_session_run_hooks.py:692] global_step/sec: 2.45002\n",
            "I0708 10:30:27.483240 140282142955392 basic_session_run_hooks.py:260] loss = 3.0134037, step = 6100 (40.816 sec)\n",
            "I0708 10:31:08.195122 140282142955392 basic_session_run_hooks.py:692] global_step/sec: 2.45622\n",
            "I0708 10:31:08.196199 140282142955392 basic_session_run_hooks.py:260] loss = 3.8108146, step = 6200 (40.713 sec)\n",
            "I0708 10:31:48.998593 140282142955392 basic_session_run_hooks.py:692] global_step/sec: 2.45078\n",
            "I0708 10:31:48.999784 140282142955392 basic_session_run_hooks.py:260] loss = 3.2618105, step = 6300 (40.804 sec)\n",
            "I0708 10:32:29.650616 140282142955392 basic_session_run_hooks.py:692] global_step/sec: 2.4599\n",
            "I0708 10:32:29.651717 140282142955392 basic_session_run_hooks.py:260] loss = 4.319963, step = 6400 (40.652 sec)\n",
            "I0708 10:33:10.408263 140282142955392 basic_session_run_hooks.py:692] global_step/sec: 2.45353\n",
            "I0708 10:33:10.409178 140282142955392 basic_session_run_hooks.py:260] loss = 2.869441, step = 6500 (40.757 sec)\n",
            "I0708 10:33:51.009198 140282142955392 basic_session_run_hooks.py:692] global_step/sec: 2.463\n",
            "I0708 10:33:51.010426 140282142955392 basic_session_run_hooks.py:260] loss = 3.6417422, step = 6600 (40.601 sec)\n",
            "I0708 10:34:31.896040 140282142955392 basic_session_run_hooks.py:692] global_step/sec: 2.44577\n",
            "I0708 10:34:31.897111 140282142955392 basic_session_run_hooks.py:260] loss = 2.6142433, step = 6700 (40.887 sec)\n",
            "I0708 10:35:12.719675 140282142955392 basic_session_run_hooks.py:692] global_step/sec: 2.44956\n",
            "I0708 10:35:12.720753 140282142955392 basic_session_run_hooks.py:260] loss = 2.4214358, step = 6800 (40.824 sec)\n",
            "I0708 10:35:53.472325 140282142955392 basic_session_run_hooks.py:692] global_step/sec: 2.45383\n",
            "I0708 10:35:53.473508 140282142955392 basic_session_run_hooks.py:260] loss = 2.3898256, step = 6900 (40.753 sec)\n",
            "I0708 10:36:34.185588 140282142955392 basic_session_run_hooks.py:692] global_step/sec: 2.4562\n",
            "I0708 10:36:34.186645 140282142955392 basic_session_run_hooks.py:260] loss = 3.2827125, step = 7000 (40.713 sec)\n",
            "I0708 10:37:15.262632 140282142955392 basic_session_run_hooks.py:692] global_step/sec: 2.43445\n",
            "I0708 10:37:15.263608 140282142955392 basic_session_run_hooks.py:260] loss = 3.146465, step = 7100 (41.077 sec)\n",
            "I0708 10:37:53.825656 140282142955392 basic_session_run_hooks.py:606] Saving checkpoints for 7196 into training/model.ckpt.\n",
            "W0708 10:37:53.920074 140282142955392 deprecation.py:323] From /usr/local/lib/python3.6/dist-packages/tensorflow/python/training/saver.py:960: remove_checkpoint (from tensorflow.python.training.checkpoint_management) is deprecated and will be removed in a future version.\n",
            "Instructions for updating:\n",
            "Use standard file APIs to delete files with this prefix.\n",
            "I0708 10:37:55.978348 140282142955392 estimator.py:1145] Calling model_fn.\n",
            "I0708 10:37:58.956858 140282142955392 convolutional_box_predictor.py:151] depth of additional conv before box predictor: 0\n",
            "I0708 10:37:58.992118 140282142955392 convolutional_box_predictor.py:151] depth of additional conv before box predictor: 0\n",
            "I0708 10:37:59.025679 140282142955392 convolutional_box_predictor.py:151] depth of additional conv before box predictor: 0\n",
            "I0708 10:37:59.061102 140282142955392 convolutional_box_predictor.py:151] depth of additional conv before box predictor: 0\n",
            "I0708 10:37:59.094830 140282142955392 convolutional_box_predictor.py:151] depth of additional conv before box predictor: 0\n",
            "I0708 10:37:59.135810 140282142955392 convolutional_box_predictor.py:151] depth of additional conv before box predictor: 0\n",
            "I0708 10:38:00.916424 140282142955392 estimator.py:1147] Done calling model_fn.\n",
            "I0708 10:38:00.934418 140282142955392 evaluation.py:255] Starting evaluation at 2019-07-08T10:38:00Z\n",
            "I0708 10:38:01.389435 140282142955392 monitored_session.py:240] Graph was finalized.\n",
            "2019-07-08 10:38:01.390054: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:1005] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n",
            "2019-07-08 10:38:01.390469: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1640] Found device 0 with properties: \n",
            "name: Tesla T4 major: 7 minor: 5 memoryClockRate(GHz): 1.59\n",
            "pciBusID: 0000:00:04.0\n",
            "2019-07-08 10:38:01.390598: I tensorflow/stream_executor/platform/default/dso_loader.cc:42] Successfully opened dynamic library libcudart.so.10.0\n",
            "2019-07-08 10:38:01.390622: I tensorflow/stream_executor/platform/default/dso_loader.cc:42] Successfully opened dynamic library libcublas.so.10.0\n",
            "2019-07-08 10:38:01.390647: I tensorflow/stream_executor/platform/default/dso_loader.cc:42] Successfully opened dynamic library libcufft.so.10.0\n",
            "2019-07-08 10:38:01.390667: I tensorflow/stream_executor/platform/default/dso_loader.cc:42] Successfully opened dynamic library libcurand.so.10.0\n",
            "2019-07-08 10:38:01.390687: I tensorflow/stream_executor/platform/default/dso_loader.cc:42] Successfully opened dynamic library libcusolver.so.10.0\n",
            "2019-07-08 10:38:01.390710: I tensorflow/stream_executor/platform/default/dso_loader.cc:42] Successfully opened dynamic library libcusparse.so.10.0\n",
            "2019-07-08 10:38:01.390734: I tensorflow/stream_executor/platform/default/dso_loader.cc:42] Successfully opened dynamic library libcudnn.so.7\n",
            "2019-07-08 10:38:01.390828: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:1005] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n",
            "2019-07-08 10:38:01.391204: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:1005] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n",
            "2019-07-08 10:38:01.391505: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1763] Adding visible gpu devices: 0\n",
            "2019-07-08 10:38:01.391548: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1181] Device interconnect StreamExecutor with strength 1 edge matrix:\n",
            "2019-07-08 10:38:01.391561: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1187]      0 \n",
            "2019-07-08 10:38:01.391572: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1200] 0:   N \n",
            "2019-07-08 10:38:01.391809: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:1005] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n",
            "2019-07-08 10:38:01.392145: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:1005] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n",
            "2019-07-08 10:38:01.392451: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1326] Created TensorFlow device (/job:localhost/replica:0/task:0/device:GPU:0 with 14202 MB memory) -> physical GPU (device: 0, name: Tesla T4, pci bus id: 0000:00:04.0, compute capability: 7.5)\n",
            "I0708 10:38:01.393544 140282142955392 saver.py:1280] Restoring parameters from training/model.ckpt-7196\n",
            "I0708 10:38:02.294210 140282142955392 session_manager.py:500] Running local_init_op.\n",
            "I0708 10:38:02.404612 140282142955392 session_manager.py:502] Done running local_init_op.\n",
            "I0708 10:38:04.970592 140280368703232 coco_evaluation.py:200] Performing evaluation on 17 images.\n",
            "creating index...\n",
            "index created!\n",
            "I0708 10:38:04.971030 140280368703232 coco_tools.py:109] Loading and preparing annotation results...\n",
            "I0708 10:38:04.972478 140280368703232 coco_tools.py:131] DONE (t=0.00s)\n",
            "creating index...\n",
            "index created!\n",
            "Running per image evaluation...\n",
            "Evaluate annotation type *bbox*\n",
            "DONE (t=0.08s).\n",
            "Accumulating evaluation results...\n",
            "DONE (t=0.04s).\n",
            " Average Precision  (AP) @[ IoU=0.50:0.95 | area=   all | maxDets=100 ] = 0.188\n",
            " Average Precision  (AP) @[ IoU=0.50      | area=   all | maxDets=100 ] = 0.462\n",
            " Average Precision  (AP) @[ IoU=0.75      | area=   all | maxDets=100 ] = 0.120\n",
            " Average Precision  (AP) @[ IoU=0.50:0.95 | area= small | maxDets=100 ] = -1.000\n",
            " Average Precision  (AP) @[ IoU=0.50:0.95 | area=medium | maxDets=100 ] = 0.099\n",
            " Average Precision  (AP) @[ IoU=0.50:0.95 | area= large | maxDets=100 ] = 0.200\n",
            " Average Recall     (AR) @[ IoU=0.50:0.95 | area=   all | maxDets=  1 ] = 0.202\n",
            " Average Recall     (AR) @[ IoU=0.50:0.95 | area=   all | maxDets= 10 ] = 0.249\n",
            " Average Recall     (AR) @[ IoU=0.50:0.95 | area=   all | maxDets=100 ] = 0.251\n",
            " Average Recall     (AR) @[ IoU=0.50:0.95 | area= small | maxDets=100 ] = -1.000\n",
            " Average Recall     (AR) @[ IoU=0.50:0.95 | area=medium | maxDets=100 ] = 0.113\n",
            " Average Recall     (AR) @[ IoU=0.50:0.95 | area= large | maxDets=100 ] = 0.281\n",
            "I0708 10:38:05.409991 140282142955392 evaluation.py:275] Finished evaluation at 2019-07-08-10:38:05\n",
            "I0708 10:38:05.410246 140282142955392 estimator.py:2039] Saving dict for global step 7196: DetectionBoxes_Precision/mAP = 0.18834873, DetectionBoxes_Precision/mAP (large) = 0.199574, DetectionBoxes_Precision/mAP (medium) = 0.098632514, DetectionBoxes_Precision/mAP (small) = -1.0, DetectionBoxes_Precision/mAP@.50IOU = 0.46220484, DetectionBoxes_Precision/mAP@.75IOU = 0.120132014, DetectionBoxes_Recall/AR@1 = 0.20222223, DetectionBoxes_Recall/AR@10 = 0.2488889, DetectionBoxes_Recall/AR@100 = 0.25111112, DetectionBoxes_Recall/AR@100 (large) = 0.28133333, DetectionBoxes_Recall/AR@100 (medium) = 0.1125, DetectionBoxes_Recall/AR@100 (small) = -1.0, Loss/classification_loss = 10.102724, Loss/localization_loss = 1.925247, Loss/regularization_loss = 0.27852598, Loss/total_loss = 12.306497, global_step = 7196, learning_rate = 0.004, loss = 12.306497\n",
            "I0708 10:38:05.413939 140282142955392 estimator.py:2099] Saving 'checkpoint_path' summary for global step 7196: training/model.ckpt-7196\n",
            "I0708 10:38:07.550745 140282142955392 basic_session_run_hooks.py:692] global_step/sec: 1.91248\n",
            "I0708 10:38:07.551733 140282142955392 basic_session_run_hooks.py:260] loss = 2.8285677, step = 7200 (52.288 sec)\n",
            "I0708 10:38:48.141991 140282142955392 basic_session_run_hooks.py:692] global_step/sec: 2.46358\n",
            "I0708 10:38:48.143152 140282142955392 basic_session_run_hooks.py:260] loss = 3.3129697, step = 7300 (40.591 sec)\n",
            "I0708 10:39:28.721227 140282142955392 basic_session_run_hooks.py:692] global_step/sec: 2.46433\n",
            "I0708 10:39:28.722563 140282142955392 basic_session_run_hooks.py:260] loss = 2.4098291, step = 7400 (40.579 sec)\n",
            "I0708 10:40:09.453016 140282142955392 basic_session_run_hooks.py:692] global_step/sec: 2.45508\n",
            "I0708 10:40:09.454309 140282142955392 basic_session_run_hooks.py:260] loss = 2.5272403, step = 7500 (40.732 sec)\n",
            "I0708 10:40:50.068761 140282142955392 basic_session_run_hooks.py:692] global_step/sec: 2.4621\n",
            "I0708 10:40:50.069701 140282142955392 basic_session_run_hooks.py:260] loss = 4.4384165, step = 7600 (40.615 sec)\n",
            "I0708 10:41:30.731681 140282142955392 basic_session_run_hooks.py:692] global_step/sec: 2.45924\n",
            "I0708 10:41:30.732753 140282142955392 basic_session_run_hooks.py:260] loss = 2.2990375, step = 7700 (40.663 sec)\n",
            "I0708 10:42:11.351873 140282142955392 basic_session_run_hooks.py:692] global_step/sec: 2.46183\n",
            "I0708 10:42:11.352917 140282142955392 basic_session_run_hooks.py:260] loss = 2.462513, step = 7800 (40.620 sec)\n",
            "I0708 10:42:51.953013 140282142955392 basic_session_run_hooks.py:692] global_step/sec: 2.46299\n",
            "I0708 10:42:51.954033 140282142955392 basic_session_run_hooks.py:260] loss = 2.9455245, step = 7900 (40.601 sec)\n",
            "I0708 10:43:32.401960 140282142955392 basic_session_run_hooks.py:692] global_step/sec: 2.47225\n",
            "I0708 10:43:32.402913 140282142955392 basic_session_run_hooks.py:260] loss = 3.880114, step = 8000 (40.449 sec)\n",
            "I0708 10:44:12.973496 140282142955392 basic_session_run_hooks.py:692] global_step/sec: 2.46478\n",
            "I0708 10:44:12.974544 140282142955392 basic_session_run_hooks.py:260] loss = 2.9620368, step = 8100 (40.572 sec)\n",
            "I0708 10:44:53.488412 140282142955392 basic_session_run_hooks.py:692] global_step/sec: 2.46823\n",
            "I0708 10:44:53.489541 140282142955392 basic_session_run_hooks.py:260] loss = 3.0913136, step = 8200 (40.515 sec)\n",
            "I0708 10:45:34.104879 140282142955392 basic_session_run_hooks.py:692] global_step/sec: 2.46206\n",
            "I0708 10:45:34.105818 140282142955392 basic_session_run_hooks.py:260] loss = 2.3363082, step = 8300 (40.616 sec)\n",
            "I0708 10:46:14.396608 140282142955392 basic_session_run_hooks.py:692] global_step/sec: 2.4819\n",
            "I0708 10:46:14.397620 140282142955392 basic_session_run_hooks.py:260] loss = 3.2560825, step = 8400 (40.292 sec)\n",
            "I0708 10:46:55.018932 140282142955392 basic_session_run_hooks.py:692] global_step/sec: 2.4617\n",
            "I0708 10:46:55.020092 140282142955392 basic_session_run_hooks.py:260] loss = 3.3134973, step = 8500 (40.622 sec)\n",
            "I0708 10:47:35.540472 140282142955392 basic_session_run_hooks.py:692] global_step/sec: 2.46783\n",
            "I0708 10:47:35.541457 140282142955392 basic_session_run_hooks.py:260] loss = 3.8565803, step = 8600 (40.521 sec)\n",
            "I0708 10:47:54.201760 140282142955392 basic_session_run_hooks.py:606] Saving checkpoints for 8647 into training/model.ckpt.\n",
            "I0708 10:47:56.353483 140282142955392 estimator.py:1145] Calling model_fn.\n",
            "I0708 10:47:59.311250 140282142955392 convolutional_box_predictor.py:151] depth of additional conv before box predictor: 0\n",
            "I0708 10:47:59.345982 140282142955392 convolutional_box_predictor.py:151] depth of additional conv before box predictor: 0\n",
            "I0708 10:47:59.380435 140282142955392 convolutional_box_predictor.py:151] depth of additional conv before box predictor: 0\n",
            "I0708 10:47:59.414949 140282142955392 convolutional_box_predictor.py:151] depth of additional conv before box predictor: 0\n",
            "I0708 10:47:59.449542 140282142955392 convolutional_box_predictor.py:151] depth of additional conv before box predictor: 0\n",
            "I0708 10:47:59.483099 140282142955392 convolutional_box_predictor.py:151] depth of additional conv before box predictor: 0\n",
            "I0708 10:48:01.260837 140282142955392 estimator.py:1147] Done calling model_fn.\n",
            "I0708 10:48:01.278987 140282142955392 evaluation.py:255] Starting evaluation at 2019-07-08T10:48:01Z\n",
            "I0708 10:48:01.744391 140282142955392 monitored_session.py:240] Graph was finalized.\n",
            "2019-07-08 10:48:01.745040: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:1005] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n",
            "2019-07-08 10:48:01.745418: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1640] Found device 0 with properties: \n",
            "name: Tesla T4 major: 7 minor: 5 memoryClockRate(GHz): 1.59\n",
            "pciBusID: 0000:00:04.0\n",
            "2019-07-08 10:48:01.745564: I tensorflow/stream_executor/platform/default/dso_loader.cc:42] Successfully opened dynamic library libcudart.so.10.0\n",
            "2019-07-08 10:48:01.745598: I tensorflow/stream_executor/platform/default/dso_loader.cc:42] Successfully opened dynamic library libcublas.so.10.0\n",
            "2019-07-08 10:48:01.745620: I tensorflow/stream_executor/platform/default/dso_loader.cc:42] Successfully opened dynamic library libcufft.so.10.0\n",
            "2019-07-08 10:48:01.745649: I tensorflow/stream_executor/platform/default/dso_loader.cc:42] Successfully opened dynamic library libcurand.so.10.0\n",
            "2019-07-08 10:48:01.745685: I tensorflow/stream_executor/platform/default/dso_loader.cc:42] Successfully opened dynamic library libcusolver.so.10.0\n",
            "2019-07-08 10:48:01.745710: I tensorflow/stream_executor/platform/default/dso_loader.cc:42] Successfully opened dynamic library libcusparse.so.10.0\n",
            "2019-07-08 10:48:01.745736: I tensorflow/stream_executor/platform/default/dso_loader.cc:42] Successfully opened dynamic library libcudnn.so.7\n",
            "2019-07-08 10:48:01.745821: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:1005] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n",
            "2019-07-08 10:48:01.746178: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:1005] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n",
            "2019-07-08 10:48:01.746472: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1763] Adding visible gpu devices: 0\n",
            "2019-07-08 10:48:01.746551: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1181] Device interconnect StreamExecutor with strength 1 edge matrix:\n",
            "2019-07-08 10:48:01.746569: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1187]      0 \n",
            "2019-07-08 10:48:01.746579: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1200] 0:   N \n",
            "2019-07-08 10:48:01.746835: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:1005] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n",
            "2019-07-08 10:48:01.747199: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:1005] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n",
            "2019-07-08 10:48:01.747507: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1326] Created TensorFlow device (/job:localhost/replica:0/task:0/device:GPU:0 with 14202 MB memory) -> physical GPU (device: 0, name: Tesla T4, pci bus id: 0000:00:04.0, compute capability: 7.5)\n",
            "I0708 10:48:01.748626 140282142955392 saver.py:1280] Restoring parameters from training/model.ckpt-8647\n",
            "I0708 10:48:02.626443 140282142955392 session_manager.py:500] Running local_init_op.\n",
            "I0708 10:48:02.744575 140282142955392 session_manager.py:502] Done running local_init_op.\n",
            "I0708 10:48:05.306499 140280360310528 coco_evaluation.py:200] Performing evaluation on 17 images.\n",
            "creating index...\n",
            "index created!\n",
            "I0708 10:48:05.309360 140280360310528 coco_tools.py:109] Loading and preparing annotation results...\n",
            "I0708 10:48:05.310685 140280360310528 coco_tools.py:131] DONE (t=0.00s)\n",
            "creating index...\n",
            "index created!\n",
            "Running per image evaluation...\n",
            "Evaluate annotation type *bbox*\n",
            "DONE (t=0.09s).\n",
            "Accumulating evaluation results...\n",
            "DONE (t=0.05s).\n",
            " Average Precision  (AP) @[ IoU=0.50:0.95 | area=   all | maxDets=100 ] = 0.265\n",
            " Average Precision  (AP) @[ IoU=0.50      | area=   all | maxDets=100 ] = 0.612\n",
            " Average Precision  (AP) @[ IoU=0.75      | area=   all | maxDets=100 ] = 0.297\n",
            " Average Precision  (AP) @[ IoU=0.50:0.95 | area= small | maxDets=100 ] = -1.000\n",
            " Average Precision  (AP) @[ IoU=0.50:0.95 | area=medium | maxDets=100 ] = 0.081\n",
            " Average Precision  (AP) @[ IoU=0.50:0.95 | area= large | maxDets=100 ] = 0.299\n",
            " Average Recall     (AR) @[ IoU=0.50:0.95 | area=   all | maxDets=  1 ] = 0.330\n",
            " Average Recall     (AR) @[ IoU=0.50:0.95 | area=   all | maxDets= 10 ] = 0.386\n",
            " Average Recall     (AR) @[ IoU=0.50:0.95 | area=   all | maxDets=100 ] = 0.386\n",
            " Average Recall     (AR) @[ IoU=0.50:0.95 | area= small | maxDets=100 ] = -1.000\n",
            " Average Recall     (AR) @[ IoU=0.50:0.95 | area=medium | maxDets=100 ] = 0.169\n",
            " Average Recall     (AR) @[ IoU=0.50:0.95 | area= large | maxDets=100 ] = 0.407\n",
            "I0708 10:48:05.752352 140282142955392 evaluation.py:275] Finished evaluation at 2019-07-08-10:48:05\n",
            "I0708 10:48:05.752601 140282142955392 estimator.py:2039] Saving dict for global step 8647: DetectionBoxes_Precision/mAP = 0.26506624, DetectionBoxes_Precision/mAP (large) = 0.2991497, DetectionBoxes_Precision/mAP (medium) = 0.08076247, DetectionBoxes_Precision/mAP (small) = -1.0, DetectionBoxes_Precision/mAP@.50IOU = 0.61222214, DetectionBoxes_Precision/mAP@.75IOU = 0.29735973, DetectionBoxes_Recall/AR@1 = 0.33, DetectionBoxes_Recall/AR@10 = 0.38555557, DetectionBoxes_Recall/AR@100 = 0.38555557, DetectionBoxes_Recall/AR@100 (large) = 0.40733334, DetectionBoxes_Recall/AR@100 (medium) = 0.16875, DetectionBoxes_Recall/AR@100 (small) = -1.0, Loss/classification_loss = 9.616568, Loss/localization_loss = 1.532796, Loss/regularization_loss = 0.28324398, Loss/total_loss = 11.43261, global_step = 8647, learning_rate = 0.004, loss = 11.43261\n",
            "I0708 10:48:05.756349 140282142955392 estimator.py:2099] Saving 'checkpoint_path' summary for global step 8647: training/model.ckpt-8647\n",
            "I0708 10:48:27.709690 140282142955392 basic_session_run_hooks.py:692] global_step/sec: 1.91684\n",
            "I0708 10:48:27.710762 140282142955392 basic_session_run_hooks.py:260] loss = 2.7519307, step = 8700 (52.169 sec)\n",
            "I0708 10:49:08.408526 140282142955392 basic_session_run_hooks.py:692] global_step/sec: 2.45707\n",
            "I0708 10:49:08.409675 140282142955392 basic_session_run_hooks.py:260] loss = 2.2061656, step = 8800 (40.699 sec)\n",
            "I0708 10:49:48.812423 140282142955392 basic_session_run_hooks.py:692] global_step/sec: 2.47501\n",
            "I0708 10:49:48.813320 140282142955392 basic_session_run_hooks.py:260] loss = 2.5169654, step = 8900 (40.404 sec)\n",
            "I0708 10:50:29.384583 140282142955392 basic_session_run_hooks.py:692] global_step/sec: 2.46474\n",
            "I0708 10:50:29.385636 140282142955392 basic_session_run_hooks.py:260] loss = 2.1437917, step = 9000 (40.572 sec)\n",
            "I0708 10:51:10.159404 140282142955392 basic_session_run_hooks.py:692] global_step/sec: 2.45249\n",
            "I0708 10:51:10.160464 140282142955392 basic_session_run_hooks.py:260] loss = 2.7190268, step = 9100 (40.775 sec)\n",
            "I0708 10:51:50.737302 140282142955392 basic_session_run_hooks.py:692] global_step/sec: 2.4644\n",
            "I0708 10:51:50.738519 140282142955392 basic_session_run_hooks.py:260] loss = 2.0954142, step = 9200 (40.578 sec)\n",
            "I0708 10:52:31.118579 140282142955392 basic_session_run_hooks.py:692] global_step/sec: 2.47639\n",
            "I0708 10:52:31.119846 140282142955392 basic_session_run_hooks.py:260] loss = 1.9278783, step = 9300 (40.381 sec)\n",
            "I0708 10:53:11.713341 140282142955392 basic_session_run_hooks.py:692] global_step/sec: 2.46337\n",
            "I0708 10:53:11.714389 140282142955392 basic_session_run_hooks.py:260] loss = 1.9779801, step = 9400 (40.595 sec)\n",
            "I0708 10:53:52.378451 140282142955392 basic_session_run_hooks.py:692] global_step/sec: 2.45911\n",
            "I0708 10:53:52.379402 140282142955392 basic_session_run_hooks.py:260] loss = 2.3122897, step = 9500 (40.665 sec)\n",
            "I0708 10:54:33.012302 140282142955392 basic_session_run_hooks.py:692] global_step/sec: 2.461\n",
            "I0708 10:54:33.013455 140282142955392 basic_session_run_hooks.py:260] loss = 2.7958908, step = 9600 (40.634 sec)\n",
            "I0708 10:55:13.693478 140282142955392 basic_session_run_hooks.py:692] global_step/sec: 2.45814\n",
            "I0708 10:55:13.694560 140282142955392 basic_session_run_hooks.py:260] loss = 2.408711, step = 9700 (40.681 sec)\n",
            "I0708 10:55:54.368145 140282142955392 basic_session_run_hooks.py:692] global_step/sec: 2.45853\n",
            "I0708 10:55:54.369344 140282142955392 basic_session_run_hooks.py:260] loss = 2.2542572, step = 9800 (40.675 sec)\n",
            "I0708 10:56:34.843634 140282142955392 basic_session_run_hooks.py:692] global_step/sec: 2.47063\n",
            "I0708 10:56:34.844860 140282142955392 basic_session_run_hooks.py:260] loss = 2.3821936, step = 9900 (40.476 sec)\n",
            "I0708 10:57:15.588579 140282142955392 basic_session_run_hooks.py:692] global_step/sec: 2.45429\n",
            "I0708 10:57:15.589528 140282142955392 basic_session_run_hooks.py:260] loss = 2.5327787, step = 10000 (40.745 sec)\n",
            "I0708 10:57:54.442412 140282142955392 basic_session_run_hooks.py:606] Saving checkpoints for 10097 into training/model.ckpt.\n",
            "I0708 10:57:57.094530 140282142955392 estimator.py:1145] Calling model_fn.\n",
            "I0708 10:57:59.505498 140282142955392 convolutional_box_predictor.py:151] depth of additional conv before box predictor: 0\n",
            "I0708 10:57:59.540693 140282142955392 convolutional_box_predictor.py:151] depth of additional conv before box predictor: 0\n",
            "I0708 10:57:59.574267 140282142955392 convolutional_box_predictor.py:151] depth of additional conv before box predictor: 0\n",
            "I0708 10:57:59.609295 140282142955392 convolutional_box_predictor.py:151] depth of additional conv before box predictor: 0\n",
            "I0708 10:57:59.642840 140282142955392 convolutional_box_predictor.py:151] depth of additional conv before box predictor: 0\n",
            "I0708 10:57:59.677229 140282142955392 convolutional_box_predictor.py:151] depth of additional conv before box predictor: 0\n",
            "I0708 10:58:01.828450 140282142955392 estimator.py:1147] Done calling model_fn.\n",
            "I0708 10:58:01.850201 140282142955392 evaluation.py:255] Starting evaluation at 2019-07-08T10:58:01Z\n",
            "I0708 10:58:02.325681 140282142955392 monitored_session.py:240] Graph was finalized.\n",
            "2019-07-08 10:58:02.326292: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:1005] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n",
            "2019-07-08 10:58:02.326659: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1640] Found device 0 with properties: \n",
            "name: Tesla T4 major: 7 minor: 5 memoryClockRate(GHz): 1.59\n",
            "pciBusID: 0000:00:04.0\n",
            "2019-07-08 10:58:02.326751: I tensorflow/stream_executor/platform/default/dso_loader.cc:42] Successfully opened dynamic library libcudart.so.10.0\n",
            "2019-07-08 10:58:02.326775: I tensorflow/stream_executor/platform/default/dso_loader.cc:42] Successfully opened dynamic library libcublas.so.10.0\n",
            "2019-07-08 10:58:02.326797: I tensorflow/stream_executor/platform/default/dso_loader.cc:42] Successfully opened dynamic library libcufft.so.10.0\n",
            "2019-07-08 10:58:02.326818: I tensorflow/stream_executor/platform/default/dso_loader.cc:42] Successfully opened dynamic library libcurand.so.10.0\n",
            "2019-07-08 10:58:02.326839: I tensorflow/stream_executor/platform/default/dso_loader.cc:42] Successfully opened dynamic library libcusolver.so.10.0\n",
            "2019-07-08 10:58:02.326858: I tensorflow/stream_executor/platform/default/dso_loader.cc:42] Successfully opened dynamic library libcusparse.so.10.0\n",
            "2019-07-08 10:58:02.326879: I tensorflow/stream_executor/platform/default/dso_loader.cc:42] Successfully opened dynamic library libcudnn.so.7\n",
            "2019-07-08 10:58:02.326959: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:1005] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n",
            "2019-07-08 10:58:02.327318: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:1005] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n",
            "2019-07-08 10:58:02.327608: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1763] Adding visible gpu devices: 0\n",
            "2019-07-08 10:58:02.327652: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1181] Device interconnect StreamExecutor with strength 1 edge matrix:\n",
            "2019-07-08 10:58:02.327665: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1187]      0 \n",
            "2019-07-08 10:58:02.327677: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1200] 0:   N \n",
            "2019-07-08 10:58:02.327897: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:1005] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n",
            "2019-07-08 10:58:02.328224: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:1005] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n",
            "2019-07-08 10:58:02.328533: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1326] Created TensorFlow device (/job:localhost/replica:0/task:0/device:GPU:0 with 14202 MB memory) -> physical GPU (device: 0, name: Tesla T4, pci bus id: 0000:00:04.0, compute capability: 7.5)\n",
            "I0708 10:58:02.329590 140282142955392 saver.py:1280] Restoring parameters from training/model.ckpt-10097\n",
            "I0708 10:58:03.229449 140282142955392 session_manager.py:500] Running local_init_op.\n",
            "I0708 10:58:03.342930 140282142955392 session_manager.py:502] Done running local_init_op.\n",
            "I0708 10:58:05.850659 140280360310528 coco_evaluation.py:200] Performing evaluation on 17 images.\n",
            "creating index...\n",
            "index created!\n",
            "I0708 10:58:05.851522 140280360310528 coco_tools.py:109] Loading and preparing annotation results...\n",
            "I0708 10:58:05.852755 140280360310528 coco_tools.py:131] DONE (t=0.00s)\n",
            "creating index...\n",
            "index created!\n",
            "Running per image evaluation...\n",
            "Evaluate annotation type *bbox*\n",
            "DONE (t=0.08s).\n",
            "Accumulating evaluation results...\n",
            "DONE (t=0.06s).\n",
            " Average Precision  (AP) @[ IoU=0.50:0.95 | area=   all | maxDets=100 ] = 0.283\n",
            " Average Precision  (AP) @[ IoU=0.50      | area=   all | maxDets=100 ] = 0.669\n",
            " Average Precision  (AP) @[ IoU=0.75      | area=   all | maxDets=100 ] = 0.123\n",
            " Average Precision  (AP) @[ IoU=0.50:0.95 | area= small | maxDets=100 ] = -1.000\n",
            " Average Precision  (AP) @[ IoU=0.50:0.95 | area=medium | maxDets=100 ] = 0.169\n",
            " Average Precision  (AP) @[ IoU=0.50:0.95 | area= large | maxDets=100 ] = 0.295\n",
            " Average Recall     (AR) @[ IoU=0.50:0.95 | area=   all | maxDets=  1 ] = 0.320\n",
            " Average Recall     (AR) @[ IoU=0.50:0.95 | area=   all | maxDets= 10 ] = 0.390\n",
            " Average Recall     (AR) @[ IoU=0.50:0.95 | area=   all | maxDets=100 ] = 0.396\n",
            " Average Recall     (AR) @[ IoU=0.50:0.95 | area= small | maxDets=100 ] = -1.000\n",
            " Average Recall     (AR) @[ IoU=0.50:0.95 | area=medium | maxDets=100 ] = 0.269\n",
            " Average Recall     (AR) @[ IoU=0.50:0.95 | area= large | maxDets=100 ] = 0.407\n",
            "I0708 10:58:06.306809 140282142955392 evaluation.py:275] Finished evaluation at 2019-07-08-10:58:06\n",
            "I0708 10:58:06.307109 140282142955392 estimator.py:2039] Saving dict for global step 10097: DetectionBoxes_Precision/mAP = 0.28349137, DetectionBoxes_Precision/mAP (large) = 0.2948464, DetectionBoxes_Precision/mAP (medium) = 0.16851223, DetectionBoxes_Precision/mAP (small) = -1.0, DetectionBoxes_Precision/mAP@.50IOU = 0.6687903, DetectionBoxes_Precision/mAP@.75IOU = 0.12277228, DetectionBoxes_Recall/AR@1 = 0.32, DetectionBoxes_Recall/AR@10 = 0.39, DetectionBoxes_Recall/AR@100 = 0.39555556, DetectionBoxes_Recall/AR@100 (large) = 0.40666667, DetectionBoxes_Recall/AR@100 (medium) = 0.26875, DetectionBoxes_Recall/AR@100 (small) = -1.0, Loss/classification_loss = 8.803503, Loss/localization_loss = 1.6360642, Loss/regularization_loss = 0.2875851, Loss/total_loss = 10.727153, global_step = 10097, learning_rate = 0.004, loss = 10.727153\n",
            "I0708 10:58:06.310064 140282142955392 estimator.py:2099] Saving 'checkpoint_path' summary for global step 10097: training/model.ckpt-10097\n",
            "I0708 10:58:08.036770 140282142955392 basic_session_run_hooks.py:692] global_step/sec: 1.90664\n",
            "I0708 10:58:08.038078 140282142955392 basic_session_run_hooks.py:260] loss = 3.0278704, step = 10100 (52.449 sec)\n",
            "I0708 10:58:48.798425 140282142955392 basic_session_run_hooks.py:692] global_step/sec: 2.45329\n",
            "I0708 10:58:48.799622 140282142955392 basic_session_run_hooks.py:260] loss = 2.3357158, step = 10200 (40.762 sec)\n",
            "I0708 10:59:29.324161 140282142955392 basic_session_run_hooks.py:692] global_step/sec: 2.46756\n",
            "I0708 10:59:29.325185 140282142955392 basic_session_run_hooks.py:260] loss = 3.5297008, step = 10300 (40.526 sec)\n",
            "I0708 11:00:10.113368 140282142955392 basic_session_run_hooks.py:692] global_step/sec: 2.45163\n",
            "I0708 11:00:10.114480 140282142955392 basic_session_run_hooks.py:260] loss = 2.542734, step = 10400 (40.789 sec)\n",
            "I0708 11:00:50.790623 140282142955392 basic_session_run_hooks.py:692] global_step/sec: 2.45837\n",
            "I0708 11:00:50.791563 140282142955392 basic_session_run_hooks.py:260] loss = 2.436592, step = 10500 (40.677 sec)\n",
            "I0708 11:01:31.575260 140282142955392 basic_session_run_hooks.py:692] global_step/sec: 2.4519\n",
            "I0708 11:01:31.576335 140282142955392 basic_session_run_hooks.py:260] loss = 2.229622, step = 10600 (40.785 sec)\n",
            "I0708 11:02:12.201770 140282142955392 basic_session_run_hooks.py:692] global_step/sec: 2.46145\n",
            "I0708 11:02:12.202796 140282142955392 basic_session_run_hooks.py:260] loss = 2.0288918, step = 10700 (40.626 sec)\n",
            "I0708 11:02:53.099175 140282142955392 basic_session_run_hooks.py:692] global_step/sec: 2.44514\n",
            "I0708 11:02:53.100581 140282142955392 basic_session_run_hooks.py:260] loss = 2.8455238, step = 10800 (40.898 sec)\n",
            "I0708 11:03:33.613913 140282142955392 basic_session_run_hooks.py:692] global_step/sec: 2.46824\n",
            "I0708 11:03:33.615203 140282142955392 basic_session_run_hooks.py:260] loss = 3.4762275, step = 10900 (40.515 sec)\n",
            "I0708 11:04:14.370916 140282142955392 basic_session_run_hooks.py:692] global_step/sec: 2.45356\n",
            "I0708 11:04:14.374312 140282142955392 basic_session_run_hooks.py:260] loss = 2.2463984, step = 11000 (40.759 sec)\n",
            "I0708 11:04:55.204012 140282142955392 basic_session_run_hooks.py:692] global_step/sec: 2.44899\n",
            "I0708 11:04:55.204904 140282142955392 basic_session_run_hooks.py:260] loss = 2.6599686, step = 11100 (40.831 sec)\n",
            "I0708 11:05:35.896768 140282142955392 basic_session_run_hooks.py:692] global_step/sec: 2.45744\n",
            "I0708 11:05:35.897971 140282142955392 basic_session_run_hooks.py:260] loss = 2.1553159, step = 11200 (40.693 sec)\n",
            "I0708 11:06:16.659918 140282142955392 basic_session_run_hooks.py:692] global_step/sec: 2.4532\n",
            "I0708 11:06:16.660977 140282142955392 basic_session_run_hooks.py:260] loss = 4.442728, step = 11300 (40.763 sec)\n",
            "I0708 11:06:57.312564 140282142955392 basic_session_run_hooks.py:692] global_step/sec: 2.45986\n",
            "I0708 11:06:57.313500 140282142955392 basic_session_run_hooks.py:260] loss = 2.2309318, step = 11400 (40.653 sec)\n",
            "I0708 11:07:37.810922 140282142955392 basic_session_run_hooks.py:692] global_step/sec: 2.46924\n",
            "I0708 11:07:37.811967 140282142955392 basic_session_run_hooks.py:260] loss = 3.580533, step = 11500 (40.498 sec)\n",
            "I0708 11:07:54.652709 140282142955392 basic_session_run_hooks.py:606] Saving checkpoints for 11542 into training/model.ckpt.\n",
            "I0708 11:07:56.806252 140282142955392 estimator.py:1145] Calling model_fn.\n",
            "I0708 11:07:59.252067 140282142955392 convolutional_box_predictor.py:151] depth of additional conv before box predictor: 0\n",
            "I0708 11:07:59.286828 140282142955392 convolutional_box_predictor.py:151] depth of additional conv before box predictor: 0\n",
            "I0708 11:07:59.320965 140282142955392 convolutional_box_predictor.py:151] depth of additional conv before box predictor: 0\n",
            "I0708 11:07:59.355581 140282142955392 convolutional_box_predictor.py:151] depth of additional conv before box predictor: 0\n",
            "I0708 11:07:59.389295 140282142955392 convolutional_box_predictor.py:151] depth of additional conv before box predictor: 0\n",
            "I0708 11:07:59.423384 140282142955392 convolutional_box_predictor.py:151] depth of additional conv before box predictor: 0\n",
            "I0708 11:08:01.746222 140282142955392 estimator.py:1147] Done calling model_fn.\n",
            "I0708 11:08:01.764803 140282142955392 evaluation.py:255] Starting evaluation at 2019-07-08T11:08:01Z\n",
            "I0708 11:08:02.216717 140282142955392 monitored_session.py:240] Graph was finalized.\n",
            "2019-07-08 11:08:02.217336: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:1005] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n",
            "2019-07-08 11:08:02.217701: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1640] Found device 0 with properties: \n",
            "name: Tesla T4 major: 7 minor: 5 memoryClockRate(GHz): 1.59\n",
            "pciBusID: 0000:00:04.0\n",
            "2019-07-08 11:08:02.217791: I tensorflow/stream_executor/platform/default/dso_loader.cc:42] Successfully opened dynamic library libcudart.so.10.0\n",
            "2019-07-08 11:08:02.217819: I tensorflow/stream_executor/platform/default/dso_loader.cc:42] Successfully opened dynamic library libcublas.so.10.0\n",
            "2019-07-08 11:08:02.217850: I tensorflow/stream_executor/platform/default/dso_loader.cc:42] Successfully opened dynamic library libcufft.so.10.0\n",
            "2019-07-08 11:08:02.217874: I tensorflow/stream_executor/platform/default/dso_loader.cc:42] Successfully opened dynamic library libcurand.so.10.0\n",
            "2019-07-08 11:08:02.217909: I tensorflow/stream_executor/platform/default/dso_loader.cc:42] Successfully opened dynamic library libcusolver.so.10.0\n",
            "2019-07-08 11:08:02.217930: I tensorflow/stream_executor/platform/default/dso_loader.cc:42] Successfully opened dynamic library libcusparse.so.10.0\n",
            "2019-07-08 11:08:02.217951: I tensorflow/stream_executor/platform/default/dso_loader.cc:42] Successfully opened dynamic library libcudnn.so.7\n",
            "2019-07-08 11:08:02.218031: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:1005] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n",
            "2019-07-08 11:08:02.218404: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:1005] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n",
            "2019-07-08 11:08:02.218687: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1763] Adding visible gpu devices: 0\n",
            "2019-07-08 11:08:02.218730: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1181] Device interconnect StreamExecutor with strength 1 edge matrix:\n",
            "2019-07-08 11:08:02.218743: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1187]      0 \n",
            "2019-07-08 11:08:02.218753: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1200] 0:   N \n",
            "2019-07-08 11:08:02.218977: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:1005] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n",
            "2019-07-08 11:08:02.219320: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:1005] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n",
            "2019-07-08 11:08:02.219620: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1326] Created TensorFlow device (/job:localhost/replica:0/task:0/device:GPU:0 with 14202 MB memory) -> physical GPU (device: 0, name: Tesla T4, pci bus id: 0000:00:04.0, compute capability: 7.5)\n",
            "I0708 11:08:02.220768 140282142955392 saver.py:1280] Restoring parameters from training/model.ckpt-11542\n",
            "I0708 11:08:03.119548 140282142955392 session_manager.py:500] Running local_init_op.\n",
            "I0708 11:08:03.241914 140282142955392 session_manager.py:502] Done running local_init_op.\n",
            "I0708 11:08:05.825727 140280360310528 coco_evaluation.py:200] Performing evaluation on 17 images.\n",
            "creating index...\n",
            "index created!\n",
            "I0708 11:08:05.826068 140280360310528 coco_tools.py:109] Loading and preparing annotation results...\n",
            "I0708 11:08:05.827207 140280360310528 coco_tools.py:131] DONE (t=0.00s)\n",
            "creating index...\n",
            "index created!\n",
            "Running per image evaluation...\n",
            "Evaluate annotation type *bbox*\n",
            "DONE (t=0.08s).\n",
            "Accumulating evaluation results...\n",
            "DONE (t=0.05s).\n",
            " Average Precision  (AP) @[ IoU=0.50:0.95 | area=   all | maxDets=100 ] = 0.293\n",
            " Average Precision  (AP) @[ IoU=0.50      | area=   all | maxDets=100 ] = 0.643\n",
            " Average Precision  (AP) @[ IoU=0.75      | area=   all | maxDets=100 ] = 0.187\n",
            " Average Precision  (AP) @[ IoU=0.50:0.95 | area= small | maxDets=100 ] = -1.000\n",
            " Average Precision  (AP) @[ IoU=0.50:0.95 | area=medium | maxDets=100 ] = 0.081\n",
            " Average Precision  (AP) @[ IoU=0.50:0.95 | area= large | maxDets=100 ] = 0.375\n",
            " Average Recall     (AR) @[ IoU=0.50:0.95 | area=   all | maxDets=  1 ] = 0.371\n",
            " Average Recall     (AR) @[ IoU=0.50:0.95 | area=   all | maxDets= 10 ] = 0.422\n",
            " Average Recall     (AR) @[ IoU=0.50:0.95 | area=   all | maxDets=100 ] = 0.433\n",
            " Average Recall     (AR) @[ IoU=0.50:0.95 | area= small | maxDets=100 ] = -1.000\n",
            " Average Recall     (AR) @[ IoU=0.50:0.95 | area=medium | maxDets=100 ] = 0.225\n",
            " Average Recall     (AR) @[ IoU=0.50:0.95 | area= large | maxDets=100 ] = 0.503\n",
            "I0708 11:08:06.281434 140282142955392 evaluation.py:275] Finished evaluation at 2019-07-08-11:08:06\n",
            "I0708 11:08:06.281693 140282142955392 estimator.py:2039] Saving dict for global step 11542: DetectionBoxes_Precision/mAP = 0.29346249, DetectionBoxes_Precision/mAP (large) = 0.3753484, DetectionBoxes_Precision/mAP (medium) = 0.080586195, DetectionBoxes_Precision/mAP (small) = -1.0, DetectionBoxes_Precision/mAP@.50IOU = 0.6425755, DetectionBoxes_Precision/mAP@.75IOU = 0.18706557, DetectionBoxes_Recall/AR@1 = 0.37111112, DetectionBoxes_Recall/AR@10 = 0.42222223, DetectionBoxes_Recall/AR@100 = 0.43333334, DetectionBoxes_Recall/AR@100 (large) = 0.50333333, DetectionBoxes_Recall/AR@100 (medium) = 0.225, DetectionBoxes_Recall/AR@100 (small) = -1.0, Loss/classification_loss = 9.348613, Loss/localization_loss = 1.6717803, Loss/regularization_loss = 0.29167226, Loss/total_loss = 11.312066, global_step = 11542, learning_rate = 0.004, loss = 11.312066\n",
            "I0708 11:08:06.285510 140282142955392 estimator.py:2099] Saving 'checkpoint_path' summary for global step 11542: training/model.ckpt-11542\n",
            "I0708 11:08:30.365337 140282142955392 basic_session_run_hooks.py:692] global_step/sec: 1.90279\n",
            "I0708 11:08:30.366475 140282142955392 basic_session_run_hooks.py:260] loss = 2.0190513, step = 11600 (52.555 sec)\n",
            "I0708 11:09:11.178172 140282142955392 basic_session_run_hooks.py:692] global_step/sec: 2.4502\n",
            "I0708 11:09:11.179394 140282142955392 basic_session_run_hooks.py:260] loss = 3.1056178, step = 11700 (40.813 sec)\n",
            "I0708 11:09:51.849220 140282142955392 basic_session_run_hooks.py:692] global_step/sec: 2.45875\n",
            "I0708 11:09:51.850350 140282142955392 basic_session_run_hooks.py:260] loss = 2.3131127, step = 11800 (40.671 sec)\n",
            "I0708 11:10:32.644639 140282142955392 basic_session_run_hooks.py:692] global_step/sec: 2.45125\n",
            "I0708 11:10:32.645587 140282142955392 basic_session_run_hooks.py:260] loss = 2.9710734, step = 11900 (40.795 sec)\n",
            "I0708 11:11:13.781697 140282142955392 basic_session_run_hooks.py:692] global_step/sec: 2.4309\n",
            "I0708 11:11:13.782851 140282142955392 basic_session_run_hooks.py:260] loss = 2.5019393, step = 12000 (41.137 sec)\n",
            "I0708 11:11:54.495316 140282142955392 basic_session_run_hooks.py:692] global_step/sec: 2.45618\n",
            "I0708 11:11:54.496263 140282142955392 basic_session_run_hooks.py:260] loss = 2.035029, step = 12100 (40.713 sec)\n",
            "I0708 11:12:34.997550 140282142955392 basic_session_run_hooks.py:692] global_step/sec: 2.469\n",
            "I0708 11:12:34.998512 140282142955392 basic_session_run_hooks.py:260] loss = 2.6555073, step = 12200 (40.502 sec)\n",
            "I0708 11:13:15.681674 140282142955392 basic_session_run_hooks.py:692] global_step/sec: 2.45796\n",
            "I0708 11:13:15.682796 140282142955392 basic_session_run_hooks.py:260] loss = 2.1659532, step = 12300 (40.684 sec)\n",
            "I0708 11:13:56.411083 140282142955392 basic_session_run_hooks.py:692] global_step/sec: 2.45523\n",
            "I0708 11:13:56.412187 140282142955392 basic_session_run_hooks.py:260] loss = 2.2343569, step = 12400 (40.729 sec)\n",
            "I0708 11:14:36.997219 140282142955392 basic_session_run_hooks.py:692] global_step/sec: 2.46389\n",
            "I0708 11:14:36.998354 140282142955392 basic_session_run_hooks.py:260] loss = 2.8007724, step = 12500 (40.586 sec)\n",
            "I0708 11:15:17.642989 140282142955392 basic_session_run_hooks.py:692] global_step/sec: 2.46028\n",
            "I0708 11:15:17.644229 140282142955392 basic_session_run_hooks.py:260] loss = 1.7859675, step = 12600 (40.646 sec)\n",
            "I0708 11:15:58.438520 140282142955392 basic_session_run_hooks.py:692] global_step/sec: 2.45125\n",
            "I0708 11:15:58.439698 140282142955392 basic_session_run_hooks.py:260] loss = 1.8593421, step = 12700 (40.795 sec)\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "GVjUm68YPBs8",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "!zip -r /content/damagecar.zip /content/Folder_To_Zip"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "rjhPT9iPSJ6T",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "! curl -s http://localhost:4040/api/tunnels | python3 -c \\\n",
        "    \"import sys, json; print(json.load(sys.stdin)['tunnels'][0]['public_url'])\""
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "JDddx2rPfex9",
        "colab_type": "text"
      },
      "source": [
        "## Train the model"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "KP-tUdtnRybs",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "!ls {model_dir}"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "_1Nrqw3nqnCh",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# Legacy way of training(also works).\n",
        "# !python /content/models/research/object_detection/legacy/train.py --logtostderr --train_dir={model_dir} --pipeline_config_path={pipeline_fname}"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "OmSESMetj1sa",
        "colab_type": "text"
      },
      "source": [
        "## Exporting a Trained Inference Graph\n",
        "Once your training job is complete, you need to extract the newly trained inference graph, which will be later used to perform the object detection. This can be done as follows:"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "DHoP90pUyKSq",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "import re\n",
        "import numpy as np\n",
        "\n",
        "output_directory = './fine_tuned_model'\n",
        "\n",
        "lst = os.listdir(model_dir)\n",
        "lst = [l for l in lst if 'model.ckpt-' in l and '.meta' in l]\n",
        "steps=np.array([int(re.findall('\\d+', l)[0]) for l in lst])\n",
        "last_model = lst[steps.argmax()].replace('.meta', '')\n",
        "\n",
        "last_model_path = os.path.join(model_dir, last_model)\n",
        "print(last_model_path)\n",
        "!python /content/models/research/object_detection/export_inference_graph.py \\\n",
        "    --input_type=image_tensor \\\n",
        "    --pipeline_config_path={pipeline_fname} \\\n",
        "    --output_directory={output_directory} \\\n",
        "    --trained_checkpoint_prefix={last_model_path}"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "usgBZvkz0nqD",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "!ls {output_directory}"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "p09AOThWkaQv",
        "colab_type": "text"
      },
      "source": [
        "## Download the model `.pb` file"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "CnDo1lonKgFr",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "import os\n",
        "\n",
        "pb_fname = os.path.join(os.path.abspath(output_directory), \"frozen_inference_graph.pb\")\n",
        "assert os.path.isfile(pb_fname), '`{}` not exist'.format(pb_fname)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "lHqWkLBINYoI",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "!ls -alh {pb_fname}"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "FIqnjbWYsuQw",
        "colab_type": "text"
      },
      "source": [
        "### Option1 : upload the `.pb` file to your Google Drive\n",
        "Then download it from your Google Drive to local file system.\n",
        "\n",
        "During this step, you will be prompted to enter the token."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "hAqyASIJqjae",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# Install the PyDrive wrapper & import libraries.\n",
        "# This only needs to be done once in a notebook.\n",
        "!pip install -U -q PyDrive\n",
        "from pydrive.auth import GoogleAuth\n",
        "from pydrive.drive import GoogleDrive\n",
        "from google.colab import auth\n",
        "from oauth2client.client import GoogleCredentials\n",
        "\n",
        "\n",
        "# Authenticate and create the PyDrive client.\n",
        "# This only needs to be done once in a notebook.\n",
        "auth.authenticate_user()\n",
        "gauth = GoogleAuth()\n",
        "gauth.credentials = GoogleCredentials.get_application_default()\n",
        "drive = GoogleDrive(gauth)\n",
        "\n",
        "fname = os.path.basename(pb_fname)\n",
        "# Create & upload a text file.\n",
        "uploaded = drive.CreateFile({'title': fname})\n",
        "uploaded.SetContentFile(pb_fname)\n",
        "uploaded.Upload()\n",
        "print('Uploaded file with ID {}'.format(uploaded.get('id')))"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "2FKFq8RXs6bs",
        "colab_type": "text"
      },
      "source": [
        "### Option2 :  Download the `.pb` file directly to your local file system\n",
        "This method may not be stable when downloading large files like the model `.pb` file. Try **option 1** instead if not working."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "-bP0iMMnnr77",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "from google.colab import files\n",
        "files.download(pb_fname)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "MFyCeiBb9BbS",
        "colab_type": "text"
      },
      "source": [
        "### Download the `label_map.pbtxt` file"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "K1TbL6Ox8q6Z",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "from google.colab import files\n",
        "files.download(label_map_pbtxt_fname)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "iUmAo9foa1xq",
        "colab_type": "text"
      },
      "source": [
        "### Download the modified pipline file\n",
        "If you plan to use OpenVINO toolkit to convert the `.pb` file to inference faster on Intel's hardware (CPU/GPU, Movidius, etc.)"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "pql2QpemazE1",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "files.download(pipeline_fname)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "w1AgBj1l0v_W",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# !tar cfz fine_tuned_model.tar.gz fine_tuned_model\n",
        "# from google.colab import files\n",
        "# files.download('fine_tuned_model.tar.gz')"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "mz1gX19GlVW7",
        "colab_type": "text"
      },
      "source": [
        "## Run inference test\n",
        "Test with images in repository `object_detection_demo/test` directory."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Pzj9A4e5mj5l",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "import os\n",
        "import glob\n",
        "\n",
        "# Path to frozen detection graph. This is the actual model that is used for the object detection.\n",
        "PATH_TO_CKPT = pb_fname\n",
        "\n",
        "# List of the strings that is used to add correct label for each box.\n",
        "PATH_TO_LABELS = label_map_pbtxt_fname\n",
        "\n",
        "# If you want to test the code with your images, just add images files to the PATH_TO_TEST_IMAGES_DIR.\n",
        "PATH_TO_TEST_IMAGES_DIR =  os.path.join(repo_dir_path, \"test\")\n",
        "\n",
        "assert os.path.isfile(pb_fname)\n",
        "assert os.path.isfile(PATH_TO_LABELS)\n",
        "TEST_IMAGE_PATHS = glob.glob(os.path.join(PATH_TO_TEST_IMAGES_DIR, \"*.*\"))\n",
        "assert len(TEST_IMAGE_PATHS) > 0, 'No image found in `{}`.'.format(PATH_TO_TEST_IMAGES_DIR)\n",
        "print(TEST_IMAGE_PATHS)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "CG5YUMdg1Po7",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "%cd /content/models/research/object_detection\n",
        "\n",
        "import numpy as np\n",
        "import os\n",
        "import six.moves.urllib as urllib\n",
        "import sys\n",
        "import tarfile\n",
        "import tensorflow as tf\n",
        "import zipfile\n",
        "\n",
        "from collections import defaultdict\n",
        "from io import StringIO\n",
        "from matplotlib import pyplot as plt\n",
        "from PIL import Image\n",
        "\n",
        "# This is needed since the notebook is stored in the object_detection folder.\n",
        "sys.path.append(\"..\")\n",
        "from object_detection.utils import ops as utils_ops\n",
        "\n",
        "\n",
        "# This is needed to display the images.\n",
        "%matplotlib inline\n",
        "\n",
        "\n",
        "from object_detection.utils import label_map_util\n",
        "\n",
        "from object_detection.utils import visualization_utils as vis_util\n",
        "\n",
        "\n",
        "detection_graph = tf.Graph()\n",
        "with detection_graph.as_default():\n",
        "    od_graph_def = tf.GraphDef()\n",
        "    with tf.gfile.GFile(PATH_TO_CKPT, 'rb') as fid:\n",
        "        serialized_graph = fid.read()\n",
        "        od_graph_def.ParseFromString(serialized_graph)\n",
        "        tf.import_graph_def(od_graph_def, name='')\n",
        "\n",
        "\n",
        "label_map = label_map_util.load_labelmap(PATH_TO_LABELS)\n",
        "categories = label_map_util.convert_label_map_to_categories(\n",
        "    label_map, max_num_classes=num_classes, use_display_name=True)\n",
        "category_index = label_map_util.create_category_index(categories)\n",
        "\n",
        "\n",
        "def load_image_into_numpy_array(image):\n",
        "    (im_width, im_height) = image.size\n",
        "    return np.array(image.getdata()).reshape(\n",
        "        (im_height, im_width, 3)).astype(np.uint8)\n",
        "\n",
        "# Size, in inches, of the output images.\n",
        "IMAGE_SIZE = (12, 8)\n",
        "\n",
        "\n",
        "def run_inference_for_single_image(image, graph):\n",
        "    with graph.as_default():\n",
        "        with tf.Session() as sess:\n",
        "            # Get handles to input and output tensors\n",
        "            ops = tf.get_default_graph().get_operations()\n",
        "            all_tensor_names = {\n",
        "                output.name for op in ops for output in op.outputs}\n",
        "            tensor_dict = {}\n",
        "            for key in [\n",
        "                'num_detections', 'detection_boxes', 'detection_scores',\n",
        "                'detection_classes', 'detection_masks'\n",
        "            ]:\n",
        "                tensor_name = key + ':0'\n",
        "                if tensor_name in all_tensor_names:\n",
        "                    tensor_dict[key] = tf.get_default_graph().get_tensor_by_name(\n",
        "                        tensor_name)\n",
        "            if 'detection_masks' in tensor_dict:\n",
        "                # The following processing is only for single image\n",
        "                detection_boxes = tf.squeeze(\n",
        "                    tensor_dict['detection_boxes'], [0])\n",
        "                detection_masks = tf.squeeze(\n",
        "                    tensor_dict['detection_masks'], [0])\n",
        "                # Reframe is required to translate mask from box coordinates to image coordinates and fit the image size.\n",
        "                real_num_detection = tf.cast(\n",
        "                    tensor_dict['num_detections'][0], tf.int32)\n",
        "                detection_boxes = tf.slice(detection_boxes, [0, 0], [\n",
        "                                           real_num_detection, -1])\n",
        "                detection_masks = tf.slice(detection_masks, [0, 0, 0], [\n",
        "                                           real_num_detection, -1, -1])\n",
        "                detection_masks_reframed = utils_ops.reframe_box_masks_to_image_masks(\n",
        "                    detection_masks, detection_boxes, image.shape[0], image.shape[1])\n",
        "                detection_masks_reframed = tf.cast(\n",
        "                    tf.greater(detection_masks_reframed, 0.5), tf.uint8)\n",
        "                # Follow the convention by adding back the batch dimension\n",
        "                tensor_dict['detection_masks'] = tf.expand_dims(\n",
        "                    detection_masks_reframed, 0)\n",
        "            image_tensor = tf.get_default_graph().get_tensor_by_name('image_tensor:0')\n",
        "\n",
        "            # Run inference\n",
        "            output_dict = sess.run(tensor_dict,\n",
        "                                   feed_dict={image_tensor: np.expand_dims(image, 0)})\n",
        "\n",
        "            # all outputs are float32 numpy arrays, so convert types as appropriate\n",
        "            output_dict['num_detections'] = int(\n",
        "                output_dict['num_detections'][0])\n",
        "            output_dict['detection_classes'] = output_dict[\n",
        "                'detection_classes'][0].astype(np.uint8)\n",
        "            output_dict['detection_boxes'] = output_dict['detection_boxes'][0]\n",
        "            output_dict['detection_scores'] = output_dict['detection_scores'][0]\n",
        "            if 'detection_masks' in output_dict:\n",
        "                output_dict['detection_masks'] = output_dict['detection_masks'][0]\n",
        "    return output_dict\n",
        "\n",
        "\n",
        "for image_path in TEST_IMAGE_PATHS:\n",
        "    image = Image.open(image_path)\n",
        "    # the array based representation of the image will be used later in order to prepare the\n",
        "    # result image with boxes and labels on it.\n",
        "    image_np = load_image_into_numpy_array(image)\n",
        "    # Expand dimensions since the model expects images to have shape: [1, None, None, 3]\n",
        "    image_np_expanded = np.expand_dims(image_np, axis=0)\n",
        "    # Actual detection.\n",
        "    output_dict = run_inference_for_single_image(image_np, detection_graph)\n",
        "    # Visualization of the results of a detection.\n",
        "    vis_util.visualize_boxes_and_labels_on_image_array(\n",
        "        image_np,\n",
        "        output_dict['detection_boxes'],\n",
        "        output_dict['detection_classes'],\n",
        "        output_dict['detection_scores'],\n",
        "        category_index,\n",
        "        instance_masks=output_dict.get('detection_masks'),\n",
        "        use_normalized_coordinates=True,\n",
        "        line_thickness=8)\n",
        "    plt.figure(figsize=IMAGE_SIZE)\n",
        "    plt.imshow(image_np)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "GStNeHWPkTcN",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        ""
      ],
      "execution_count": 0,
      "outputs": []
    }
  ]
}